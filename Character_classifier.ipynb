{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOpLTnkxLzJHwgNjtAl1l+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-amy/project-codebase/blob/main/Character_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model for Letter De-Obfuscation**\n",
        "Stage 1 of MSc Project - Ashraf Muhammed Yusuf"
      ],
      "metadata": {
        "id": "qB1MMygGJSIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Colab Environment Setup**\n",
        "Open a this notebook in Google Colab and set runtime to TPU / GPU / CPU"
      ],
      "metadata": {
        "id": "-Z1sGlcxkWFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Drive so you can read data/characters and write checkpoints\n",
        "# Link to dataset:\n",
        "# https://drive.google.com/drive/folders/1sfNG1PkmTPBe1wOSQXZmfdkvR97Hn9lk?usp=sharing\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k6tumrzokilz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q tensorflow matplotlib"
      ],
      "metadata": {
        "id": "ZFxrTOM-k0nq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, mixed_precision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "aC1qbXutk2Tk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional—but useful) turn on XLA JIT for extra speed\n",
        "tf.config.optimizer.set_jit(True)"
      ],
      "metadata": {
        "id": "TlaoeI6zJQwd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Loading & Splitting**\n",
        "We'll use Keras's image_dataset_from_directory to build train/validation and test sets."
      ],
      "metadata": {
        "id": "EYLkqjfUleL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH = 64 if tf.config.list_physical_devices('TPU') else 32\n",
        "IMG_SIZE = (64, 64)\n",
        "train_dir = \"/content/drive/MyDrive/MScProject/data/characters/train\"\n",
        "test_dir = \"/content/drive/MyDrive/MScProject/data/characters/test\"\n",
        "\n",
        "def preprocess(img, label):\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32) # 0–1\n",
        "  img = tf.image.resize(img, [64, 64])\n",
        "  return img, label\n",
        "\n",
        "\n",
        "\n",
        "# Quick .png count per class\n",
        "print(\"Train .png counts:\")\n",
        "for cls in sorted(os.listdir(train_dir)):\n",
        "  pattern = os.path.join(train_dir, cls, '*.png')\n",
        "  print(f\"  {cls}: {len(glob.glob(pattern))}\")\n",
        "\n",
        "print(\"\\nTest .png counts:\")\n",
        "for cls in sorted(os.listdir(test_dir)):\n",
        "  pattern = os.path.join(test_dir, cls, '*.png')\n",
        "  print(f\"  {cls}: {len(glob.glob(pattern))}\")\n",
        "\n",
        "# Train dataset\n",
        "train_ds = (\n",
        "  tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=BATCH,\n",
        "    image_size=IMG_SIZE,\n",
        "    color_mode=\"grayscale\",\n",
        "    validation_split=0.20,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "  )\n",
        ")\n",
        "\n",
        "\n",
        "# Val dataset\n",
        "val_ds = (\n",
        "  tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=BATCH,\n",
        "    image_size=IMG_SIZE,\n",
        "    color_mode=\"grayscale\",\n",
        "    validation_split=0.20,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "OWX12CXSlwA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SIZE,\n",
        "  color_mode=\"grayscale\",\n",
        "  shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "id": "G2vP2y4wmFQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203ace79-4d2c-4506-ecbf-5c07fd2e4a6e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7655 files belonging to 26 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility to display examples from each set\n",
        "def show_examples(ds, ds_name, num=5):\n",
        "  # Take one batch\n",
        "  for images, labels in ds.take(1):\n",
        "    images = images.numpy()\n",
        "    labels = labels.numpy()\n",
        "    class_names = ds.class_names\n",
        "    break\n",
        "\n",
        "  plt.figure(figsize=(6,6))\n",
        "  for i in range(num):\n",
        "    ax = plt.subplot(3, 3, i+1)\n",
        "    img = images[i].squeeze()  # shape: (H,W) since grayscale\n",
        "    lbl = class_names[labels[i].argmax()]\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"{ds_name}: {lbl}\")\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Display 5 examples from each split\n",
        "show_examples(train_ds, \"Train\")\n",
        "show_examples(val_ds,   \"Val\")\n",
        "show_examples(test_ds,  \"Test\")"
      ],
      "metadata": {
        "id": "JhdMrFp2OSNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Preprocessing & Augmentation**"
      ],
      "metadata": {
        "id": "S_sH7vX5mZ09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset class names before piping the dataset through 'map'\n",
        "train_ds_class_names = test_ds.class_names\n",
        "val_ds_class_names = test_ds.class_names\n",
        "test_ds_class_names = test_ds.class_names"
      ],
      "metadata": {
        "id": "bNHG90gcA-mQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize and augment datasets (only the train dataset is augmented)\n",
        "normalization = layers.Rescaling(1./255)\n",
        "aug = tf.keras.Sequential([\n",
        "  layers.RandomRotation(0.1),\n",
        "  layers.RandomZoom(0.1),\n",
        "  layers.RandomTranslation(0.1,0.1)\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x,y: (aug(normalization(x)), y))\n",
        "val_ds   = val_ds.map(lambda x,y: (normalization(x), y))\n",
        "test_ds  = test_ds.map(lambda x,y: (normalization(x), y))"
      ],
      "metadata": {
        "id": "qF7WAJ6lmcqj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Architecture**\n",
        "We will define a simple yet robust CNN (grayscale)"
      ],
      "metadata": {
        "id": "k3dpHNLTmj6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model:\n",
        "# 1. Input Layer\n",
        "inputs = layers.Input(shape=(*IMG_SIZE, 1))\n",
        "# 2. First Convolution + Pooling\n",
        "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "# 3. Second Convolution + Pooling\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "# 4. Third Convolution\n",
        "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
        "# 5. Flatten to Vector\n",
        "x = layers.Flatten()(x)\n",
        "# 6. Fully‑Connected (Dense) Layer\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "# 7. Dropout Regularisation\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# 8. Output Layer\n",
        "outputs = layers.Dense(26, activation='softmax')(x)\n",
        "\n",
        "# Construct model\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "# Show model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1DI5pTqmmu8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Compilation & Callbacks**"
      ],
      "metadata": {
        "id": "XBjFMxNOmz_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "# 1. Checkpoint - saves the best model\n",
        "ckpt = callbacks.ModelCheckpoint(\n",
        "  filepath=\"/content/drive/MyDrive/MScProject/char_cnn_ckpt_best.keras\",\n",
        "  save_best_only=True,\n",
        "  monitor=\"val_loss\" # keeps only the best model\n",
        ")\n",
        "# 2. Early stopping\n",
        "es = callbacks.EarlyStopping(\n",
        "  monitor=\"val_loss\",\n",
        "  patience=6, # stop ~6 epochs after val_loss stalls\n",
        "  restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 3. Learning rate scheduler\n",
        "scheduler = callbacks.ReduceLROnPlateau(\n",
        "  monitor=\"val_loss\",\n",
        "  factor=0.5,\n",
        "  patience=3, # halve LR if val_loss hasn’t improved for 3 epochs\n",
        "  min_lr=1e-6\n",
        ")\n",
        "\n",
        "callbacks=[ckpt, es, scheduler]"
      ],
      "metadata": {
        "id": "RCwR3loom2z1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Training**"
      ],
      "metadata": {
        "id": "ZMA2hu0im55n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=50,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "D63OYOFHp410"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Evaluation**"
      ],
      "metadata": {
        "id": "ZPvzZN7Sm-ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model accuracy on test dataset\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "nFntT7z9nCmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion Matrix & Classification Report**"
      ],
      "metadata": {
        "id": "sQXB87S-qYod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather all ground-truths and predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for batch_x, batch_y in test_ds:\n",
        "  preds = model.predict(batch_x)\n",
        "  y_pred.extend(np.argmax(preds, axis=1))\n",
        "  y_true.extend(np.argmax(batch_y.numpy(), axis=1))\n",
        "\n",
        "class_names = test_ds_class_names\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)"
      ],
      "metadata": {
        "id": "x6XoURWfnLiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization**"
      ],
      "metadata": {
        "id": "Od3MCZEZqpyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=90)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QpM3qzebnPPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training curves\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.figure(figsize=(12, 4))"
      ],
      "metadata": {
        "id": "pZr3mmxwq7Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, history.history['accuracy'],    label='train_acc')\n",
        "plt.plot(epochs, history.history['val_accuracy'],label='val_acc')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "85H1cYvvrEhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, history.history['loss'],    label='train_loss')\n",
        "plt.plot(epochs, history.history['val_loss'],label='val_loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "whm7lzhFrIWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Display Misclassified Examples**"
      ],
      "metadata": {
        "id": "JCvdCMn9rUrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First flatten all test images to a single array\n",
        "images_all = np.concatenate([x.numpy() for x, y in test_ds], axis=0)\n",
        "mis_idx = [i for i, (t, p) in enumerate(zip(y_true, y_pred)) if t!=p]\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "for i, idx in enumerate(mis_idx[:9]):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  img = images_all[idx].squeeze()\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.title(f\"T:{class_names[y_true[idx]]} P:{class_names[y_pred[idx]]}\")\n",
        "  plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2bwliZqcrXpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Save & Document**"
      ],
      "metadata": {
        "id": "ObyiLx0FnRef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Export label map (a - z)\n",
        "import json\n",
        "with open(\"/content/drive/MyDrive/MScProject/label_map.json\",\"w\") as f:\n",
        "    json.dump(train_ds_class_names, f)"
      ],
      "metadata": {
        "id": "hJSuKbIXnTGX"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}
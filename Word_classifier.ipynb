{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOIsoL6HUOQQwrJSmG42YQf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-amy/project-codebase/blob/main/Word_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN Sliding-Window Model for 3-Letter Word De-Obfuscation**\n",
        "Stage 2 of MSc Project — Ashraf Muhammed Yusuf"
      ],
      "metadata": {
        "id": "RNvi5n0bLCda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Colab Environment Setup**"
      ],
      "metadata": {
        "id": "V3t0wN17LOBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q tensorflow matplotlib"
      ],
      "metadata": {
        "id": "U3XkX4M9gxev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import os, random, itertools, pathlib, math, shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf, os, numpy as np\n",
        "from glob import glob\n",
        "from tensorflow.keras import mixed_precision\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import defaultdict\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "UUMBUoObLUnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Mount Drive & define base path\n",
        "# Mount Drive so you can read datasets and write checkpoints\n",
        "# Link to dataset:\n",
        "# https://drive.google.com/drive/folders/1sfNG1PkmTPBe1wOSQXZmfdkvR97Hn9lk?usp=sharing\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "91L4Z6naS9gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional—but useful) turn on XLA JIT for extra speed\n",
        "tf.config.optimizer.set_jit(True)"
      ],
      "metadata": {
        "id": "-w2FvZZOTtyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------\n",
        "# 3-Letter Word Dataset Generator (single Colab cell)\n",
        "# ------------------------------------------------------------------\n",
        "# - Builds data/words3/{train|val|test}/{cls}/img*.png\n",
        "# - Each cls = 3-letter word from aaa … zzz  (26³ = 17 576 classes)\n",
        "# - 5 variants per word (random font/glyph + optional obfuscation)\n",
        "# - Re-uses single-letter glyphs created in Stage-1 of the project\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# Define paths & knobs\n",
        "BASE_PATH = \"/content/drive/MyDrive/MScProject\"\n",
        "GLYPH_DIR = f\"{BASE_PATH}/data/characters/train\" # Stage-1 glyphs\n",
        "OUT_ROOT = f\"{BASE_PATH}/data/words3\"\n",
        "IMG_H, IMG_W = 64, 64\n",
        "PATCH_W = IMG_W // 3 # 21 px\n",
        "VARIANTS_PER_WORD = 5\n",
        "SPREAD = (0.5, 0.4, 0.1)\n",
        "\n",
        "# Obfuscation maps - leet\n",
        "LEET = {\n",
        "  'A': ['Α', '4', 'Д', 'Ä', 'Á', 'À', 'Â', '@', 'Δ'],\n",
        "  'B': ['8', 'β', 'Β', 'В'],\n",
        "  'C': ['Ç', 'Ć', 'Č', 'С'],\n",
        "  'D': ['Ð', 'Ď'],\n",
        "  'E': ['3', 'Σ', 'Έ', 'Ε', 'Е', 'Ë', 'É', 'È', 'Ê'],\n",
        "  'F': ['Φ', 'Ƒ'],\n",
        "  'G': ['6', 'Ğ', 'Ģ', 'Γ'],\n",
        "  'H': ['Η', 'Н'],\n",
        "  'I': ['1', '|', 'Í', 'Ì', 'Î', 'Ï', 'И'],\n",
        "  'J': ['Ј'],\n",
        "  'K': ['Κ', 'К'],\n",
        "  'L': ['Ι', 'Ł', 'Ĺ', 'Л'],\n",
        "  'M': ['Μ', 'М'],\n",
        "  'N': ['Ν', 'Ń', 'Ñ', 'Н'],\n",
        "  'O': ['0', 'Θ', 'Ο', 'Ө', 'Ø', 'Ö', 'Ó', 'Ò', 'Ô'],\n",
        "  'P': ['Ρ', 'Р'],\n",
        "  'Q': ['Φ'],\n",
        "  'R': ['®', 'Я', 'Ř', 'Ŕ'],\n",
        "  'S': ['5', '$', 'Ѕ', 'Ś', 'Š'],\n",
        "  'T': ['Τ', 'Т'],\n",
        "  'U': ['Υ', 'Ц', 'Ü', 'Ú', 'Ù', 'Û'],\n",
        "  'V': ['Ѵ', 'V'],\n",
        "  'W': ['Ω', 'Ѡ', 'Ψ', 'Ш', 'Щ'],\n",
        "  'X': ['Χ', 'Ж', 'Х'],\n",
        "  'Y': ['Υ', 'Ү', 'Ý', 'Ÿ'],\n",
        "  'Z': ['Ζ', 'Ż', 'Ź', 'Ž', 'З', '2']\n",
        "}\n",
        "\n",
        "# Obfuscation maps - cyrillic look-alikes\n",
        "HOMO = {\n",
        "  'A':'Α',\n",
        "  'B':'Β',\n",
        "  'C':'С',\n",
        "  'E':'Ε',\n",
        "  'H':'Н',\n",
        "  'K':'Κ',\n",
        "  'M':'Μ',\n",
        "  'O':'О',\n",
        "  'P':'Р',\n",
        "  'T':'Τ',\n",
        "  'X':'Χ',\n",
        "  'Y':'Υ',\n",
        "  'Z':'Ζ'\n",
        "}\n",
        "\n",
        "# Obfuscation helper\n",
        "def obfuscate(char):\n",
        "  mode = random.choices(\n",
        "    (\"none\", \"leet\", \"homo\"),\n",
        "    weights=SPREAD\n",
        "  )[0]\n",
        "  if mode == \"leet\" and char in LEET:\n",
        "    return random.choice(LEET[char])\n",
        "  if mode == \"homo\" and char in HOMO:\n",
        "    return HOMO[char]\n",
        "  return char\n",
        "\n",
        "# Word-stitch helper\n",
        "def stitch_word(word, save_path):\n",
        "  \"\"\"\n",
        "  Compose a 64×64 grayscale PNG for a 3-char word.\n",
        "  Uses Stage-1 glyphs 70% of the time, else renders via PIL text.\n",
        "  \"\"\"\n",
        "  canvas = Image.new(\"L\", (IMG_W, IMG_H), color=255)\n",
        "  for idx, ch in enumerate(word):\n",
        "    # choose glyph source\n",
        "    if random.random() < 0.7: # reuse Stage-1 glyph\n",
        "      glyph = Image.open(random.choice(letter_pool[ch]))\n",
        "      glyph = glyph.resize((PATCH_W, IMG_H))\n",
        "    else: # render fresh\n",
        "      glyph = Image.new(\"L\", (PATCH_W, IMG_H), color=255)\n",
        "      draw  = ImageDraw.Draw(glyph)\n",
        "      draw.text((4, 4), obfuscate(ch), fill=0)\n",
        "    canvas.paste(glyph, (idx * PATCH_W, 0))\n",
        "  if random.random() < 0.3: # light affine jitter\n",
        "    dx = random.randint(-2, 2)\n",
        "    canvas = canvas.transform(canvas.size, Image.AFFINE, (1,0,dx,0,1,0))\n",
        "  canvas.save(save_path)\n",
        "\n",
        "# Letter-image reservoir\n",
        "letter_pool = defaultdict(list)\n",
        "for letter in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
        "  letter_pool[letter] = glob(f\"{GLYPH_DIR}/{letter}/*.png\")\n",
        "  assert letter_pool[letter], f\"No glyphs found for '{letter}'\"\n",
        "\n",
        "# SAFE-GUARD: Skip everything if dataset already exists\n",
        "if os.path.exists(OUT_ROOT) and any(os.scandir(OUT_ROOT)):\n",
        "  print(\"words3 dataset already exists — skipping generation.\")\n",
        "else:\n",
        "  # Build word lists & splits\n",
        "  words = [\"\".join(p) for p in itertools.product(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", repeat=3)]\n",
        "  random.shuffle(words)\n",
        "  n = len(words)\n",
        "  splits = {\n",
        "    \"train\": words[:int(0.70*n)],\n",
        "    \"val\"  : words[int(0.70*n):int(0.85*n)],\n",
        "    \"test\" : words[int(0.85*n):]\n",
        "  }\n",
        "\n",
        "  # Generate images\n",
        "  for split_name, word_list in splits.items():\n",
        "    for word in tqdm(word_list, desc=f\"Generating {split_name}\"):\n",
        "      cls_dir = pathlib.Path(OUT_ROOT, split_name, word)\n",
        "      cls_dir.mkdir(parents=True, exist_ok=True)\n",
        "      for k in range(VARIANTS_PER_WORD):\n",
        "        out_file = cls_dir / f\"{word}_{k}.png\"\n",
        "        stitch_word(word, out_file)\n",
        "\n",
        "  # Print results\n",
        "  print(\"Dataset generation complete.\")\n",
        "  print(\"train / val / test words :\", [len(splits[s]) for s in ('train','val','test')])\n",
        "  print(\"images per split (×5)    :\", [len(splits[s])*VARIANTS_PER_WORD for s in ('train','val','test')])"
      ],
      "metadata": {
        "id": "HY1lbUDUPCh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Load & Freeze the Single-Char Model**"
      ],
      "metadata": {
        "id": "nuumCMV4NETu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.models.load_model(f\"{BASE_PATH}/char_cnn_ckpt_best.keras\")\n",
        "base_model.trainable = False # freeze weights\n",
        "print(\"Base model frozen — params:\", base_model.count_params())"
      ],
      "metadata": {
        "id": "DidvFD0MNIT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Dataset: 3-Letter Words**"
      ],
      "metadata": {
        "id": "Jc4cJg9cNkwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH = 64 if tf.config.list_physical_devices('TPU') else 32\n",
        "IMG_H, IMG_W = 64, 64\n",
        "IMG_SHAPE   = (IMG_H, IMG_W)\n",
        "NUM_CLASSES = len(train_ds_class_names) # = 12303\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess(img, label):\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img = tf.image.resize(img, IMG_SHAPE)\n",
        "  label_oh = tf.one_hot(label, NUM_CLASSES) # pad\n",
        "  return img, label_oh\n",
        "\n",
        "def make_ds(dir_path, shuffle, batch):\n",
        "  raw = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        dir_path,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\", # int first\n",
        "        batch_size=batch,\n",
        "        image_size=IMG_SHAPE,\n",
        "        color_mode=\"grayscale\",\n",
        "        shuffle=shuffle,\n",
        "        seed=42\n",
        "  )\n",
        "  # capture the folder names before we lose them\n",
        "  class_names = raw.class_names\n",
        "\n",
        "  ds = (\n",
        "    raw.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "      .cache()\n",
        "      .shuffle(1000) if shuffle else raw.map(preprocess)\n",
        "  )\n",
        "  ds = ds.prefetch(AUTOTUNE)\n",
        "  return ds, class_names\n",
        "\n",
        "# Create datasets\n",
        "train_ds, train_ds_class_names = make_ds(f\"{OUT_ROOT}/train\", shuffle=True,  batch=BATCH)\n",
        "val_ds, val_ds_class_names = make_ds(f\"{OUT_ROOT}/val\",   shuffle=False, batch=BATCH)\n",
        "test_ds, test_ds_class_names = make_ds(f\"{OUT_ROOT}/test\",  shuffle=False, batch=BATCH)"
      ],
      "metadata": {
        "id": "9YNtUaOyNkZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Visual Sanity Check**"
      ],
      "metadata": {
        "id": "qPPLO34pNz2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_examples(ds, title, n=6):\n",
        "  imgs, lbls = next(iter(ds))\n",
        "  plt.figure(figsize=(8,3))\n",
        "  for i in range(n):\n",
        "    plt.subplot(2, n//2, i+1)\n",
        "    plt.imshow(imgs[i].numpy().squeeze(), cmap='gray')\n",
        "    plt.title(class_names[lbls[i].numpy().argmax()])\n",
        "    plt.axis('off')\n",
        "  plt.suptitle(title); plt.show()\n",
        "\n",
        "show_examples(train_ds, \"Train Samples\")"
      ],
      "metadata": {
        "id": "ONjIkH9hN2Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Build the Sliding-Window Model**"
      ],
      "metadata": {
        "id": "i4xIlbVLN-hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATCH_W = IMG_W // 3 # 21 when IMG_W = 64\n",
        "\n",
        "def extract_patch(x, idx):\n",
        "  start = idx * PATCH_W\n",
        "  return x[:, :, start:start+PATCH_W, :] # (None, 64, 21, 1)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_H, IMG_W, 1))\n",
        "logits = []\n",
        "\n",
        "for i in range(3):\n",
        "  patch = tf.keras.layers.Lambda(lambda z, i=i: extract_patch(z, i))(inputs)\n",
        "  patch = tf.keras.layers.Resizing(IMG_H, IMG_H)(patch) # -> (None, 64, 64, 1)\n",
        "  # Re-use frozen base_model (shared weights)\n",
        "  logits.append(base_model(patch)) # (None, 26)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate()(logits) # (None, 78)\n",
        "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(concat)\n",
        "\n",
        "word_model = tf.keras.Model(inputs, outputs)\n",
        "word_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "word_model.summary()"
      ],
      "metadata": {
        "id": "jVuQewrCOAhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Callbacks**"
      ],
      "metadata": {
        "id": "iWVbhlvKOMjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CKPT_DIR = f\"{BASE_PATH}/words3_ckpt_best.keras\"\n",
        "\n",
        "callbacks = [\n",
        "  # 1. Checkpoint\n",
        "  ModelCheckpoint(CKPT_DIR, save_best_only=True, monitor='val_loss'),\n",
        "  # 2. Early stopping\n",
        "  EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "  # 3. Learning rate scheduler\n",
        "  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "]"
      ],
      "metadata": {
        "id": "ifsAp6O1OOrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Train (Frozen Base)**"
      ],
      "metadata": {
        "id": "XPi4tnFGOS4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = word_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=20,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "2aai8C7KOVVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. (Optional) Fine-Tune Last Conv Block**"
      ],
      "metadata": {
        "id": "st0PdMWuOdRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Un-freeze last 3 layers of base_model\n",
        "for layer in base_model.layers[-3:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "# Re-compile with lower LR\n",
        "word_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "ft_history = word_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  initial_epoch=history.epoch[-1] + 1,\n",
        "  epochs=history.epoch[-1] + 4,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "rf-zB58mOguA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Evaluation**"
      ],
      "metadata": {
        "id": "hHMjuGLOOj5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_model = tf.keras.models.load_model(CKPT_DIR) # best checkpoint\n",
        "test_loss, test_acc = word_model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Util for plotting confusion matrix\n",
        "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      cm (np.ndarray): square confusion matrix\n",
        "      class_names (List[str]): labels in the same order used to build cm\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(10, 9))\n",
        "  im = ax.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  ax.figure.colorbar(im, ax=ax, fraction=0.045)\n",
        "\n",
        "  # axes & ticks\n",
        "  ax.set(\n",
        "    xticks=np.arange(len(class_names)),\n",
        "    yticks=np.arange(len(class_names)),\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    ylabel=\"True label\",\n",
        "    xlabel=\"Predicted label\",\n",
        "    title=title,\n",
        "  )\n",
        "  plt.setp(ax.get_xticklabels(), rotation=90, ha=\"center\", va=\"center\")\n",
        "\n",
        "  # annotate cells\n",
        "  thresh = cm.max() / 2.0\n",
        "  for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "      ax.text(\n",
        "        j, i, format(cm[i, j], \"d\"),\n",
        "        ha=\"center\", va=\"center\",\n",
        "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "        fontsize=8\n",
        "      )\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Classification report\n",
        "y_pred, y_true = [], []\n",
        "for x, y in test_ds:\n",
        "  y_pred.extend(np.argmax(word_model.predict(x), axis=1))\n",
        "  y_true.extend(np.argmax(y.numpy(), axis=1))\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Confusion matrix heat-map (optional)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, class_names, title=\"3-Letter Word Confusion Matrix\")"
      ],
      "metadata": {
        "id": "fdfVNFw1OlRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Qualitative Error Analysis**"
      ],
      "metadata": {
        "id": "WeZuj2jpOrqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a few misclassified 3-letter words\n",
        "mis_idx = [i for i,(t,p) in enumerate(zip(y_true, y_pred)) if t != p]\n",
        "show_examples(test_ds.unbatch().skip(mis_idx[0]), \"Misclassified example\")"
      ],
      "metadata": {
        "id": "KSwpu5vjOuEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
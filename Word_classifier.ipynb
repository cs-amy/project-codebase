{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-amy/project-codebase/blob/main/Word_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNvi5n0bLCda"
      },
      "source": [
        "# **CNN Sliding-Window Model for 3-Letter Word De-Obfuscation**\n",
        "Stage 2 of MSc Project — Ashraf Muhammed Yusuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3t0wN17LOBf"
      },
      "source": [
        "# **1. Colab Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3XkX4M9gxev"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UUMBUoObLUnb"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import os, sys, random, itertools, pathlib, math, shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from tensorflow.keras import mixed_precision\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import defaultdict\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "91L4Z6naS9gN",
        "outputId": "4983c4bf-3913-464f-9cd0-8ed0a09a5547",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 1.3 Mount Drive & define base path\n",
        "# Mount Drive so you can read datasets and write checkpoints\n",
        "# Link to dataset:\n",
        "# https://drive.google.com/drive/folders/1sfNG1PkmTPBe1wOSQXZmfdkvR97Hn9lk?usp=sharing\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiuZCz5QZ-mr"
      },
      "source": [
        "# **2. Data Generation**\n",
        "This block generates the 'three-letter words' dataset afresh if you do not already have it (You can access it here: https://drive.google.com/drive/folders/1kygA17GiCeCs8qTeDBEndU6TkXnEu-m7?usp=drive_link). It synthesizes three three-letter words from the character dataset (https://drive.google.com/drive/folders/1eUaTNW8zVjTArg0JszbCdCEq0tTdx89n?usp=drive_link)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KgzKPaWRcDTn"
      },
      "outputs": [],
      "source": [
        "# paths & constants\n",
        "BASE_PATH = Path(\"/content/drive/MyDrive/MScProject\")\n",
        "GLYPH_DIR = Path(f\"{BASE_PATH}/data/characters/train\")\n",
        "DATA_ROOT = Path(f\"{BASE_PATH}/data/words3\")\n",
        "CKPT_DIR = f\"{BASE_PATH}/words3_ckpt_best.keras\"\n",
        "BATCH = 128\n",
        "IMG_H = IMG_W = 64\n",
        "IMG_SHAPE = (IMG_H, IMG_W)\n",
        "PATCH_W = IMG_W // 3\n",
        "VARIANTS_PER = 5 # per word\n",
        "EXPECTED_CLASSES = 26**3 # 26³ = 17,576\n",
        "FINAL_TEST_FRAC = 0.20\n",
        "SEED = 42\n",
        "PATCH_W = IMG_W // 3 # 21 when IMG_W = 64\n",
        "N_VARIANTS = 4\n",
        "TEST_DIR   = DATA_ROOT / \"test\"\n",
        "FRACTION   = 0.15 # 15 %\n",
        "train_dir = DATA_ROOT / \"train\"\n",
        "test_dir  = DATA_ROOT / \"test\"\n",
        "\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- Generates a single ‘train/’ directory with 17 576 class folders (AAA … ZZZ)\n",
        "- Each class contains N_VARIANTS PNG images rendered on-the-fly (no external glyph reuse)\n",
        "- Obfuscation applied per-character (leet + homoglyph + random spacing jitter)\n",
        "- Idempotent: if the train folder already has 17 576 classes it exits immediately\n",
        "\"\"\"\n",
        "\n",
        "# Define font\n",
        "try:\n",
        "  FONT_PATH = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "  FONT = ImageFont.truetype(FONT_PATH, 40)\n",
        "except (IOError, OSError):\n",
        "  print(\"DejaVuSans not found; using PIL default bitmap font.\")\n",
        "  FONT = ImageFont.load_default()\n",
        "\n",
        "# fast-exit guard\n",
        "if TRAIN_DIR.exists() and len([p for p in TRAIN_DIR.iterdir() if p.is_dir()]) == EXPECTED_CLASSES:\n",
        "  print(\"words3/train already complete – nothing to do.\")\n",
        "  sys.exit(0)\n",
        "\n",
        "# mapping tables (uppercase only)\n",
        "LEET = {\n",
        "  'A': ['Α', '4', 'Д', 'Ä', 'Á', 'À', 'Â', '@', 'Δ'],\n",
        "  'B': ['8', 'β', 'Β', 'В'],\n",
        "  'C': ['Ç', 'Ć', 'Č', 'С'],\n",
        "  'D': ['Ð', 'Ď'],\n",
        "  'E': ['3', 'Σ', 'Έ', 'Ε', 'Е', 'Ë', 'É', 'È', 'Ê'],\n",
        "  'F': ['Φ', 'Ƒ'],\n",
        "  'G': ['6', 'Ğ', 'Ģ', 'Γ'],\n",
        "  'H': ['Η', 'Н'],\n",
        "  'I': ['1', '|', 'Í', 'Ì', 'Î', 'Ï', 'И'],\n",
        "  'J': ['Ј'],\n",
        "  'K': ['Κ', 'К'],\n",
        "  'L': ['Ι', 'Ł', 'Ĺ', 'Л'],\n",
        "  'M': ['Μ', 'М'],\n",
        "  'N': ['Ν', 'Ń', 'Ñ', 'Н'],\n",
        "  'O': ['0', 'Θ', 'Ο', 'Ө', 'Ø', 'Ö', 'Ó', 'Ò', 'Ô'],\n",
        "  'P': ['Ρ', 'Р'],\n",
        "  'Q': ['Φ'],\n",
        "  'R': ['®', 'Я', 'Ř', 'Ŕ'],\n",
        "  'S': ['5', '$', 'Ѕ', 'Ś', 'Š'],\n",
        "  'T': ['Τ', 'Т'],\n",
        "  'U': ['Υ', 'Ц', 'Ü', 'Ú', 'Ù', 'Û'],\n",
        "  'V': ['Ѵ', 'V'],\n",
        "  'W': ['Ω', 'Ѡ', 'Ψ', 'Ш', 'Щ'],\n",
        "  'X': ['Χ', 'Ж', 'Х'],\n",
        "  'Y': ['Υ', 'Ү', 'Ý', 'Ÿ'],\n",
        "  'Z': ['Ζ', 'Ż', 'Ź', 'Ž', 'З', '2']\n",
        "}\n",
        "HOMO = {\n",
        "  'A':'Α',\n",
        "  'B':'Β',\n",
        "  'C':'С',\n",
        "  'E':'Ε',\n",
        "  'H':'Н',\n",
        "  'K':'Κ',\n",
        "  'M':'Μ',\n",
        "  'O':'О',\n",
        "  'P':'Р',\n",
        "  'T':'Τ',\n",
        "  'X':'Χ',\n",
        "  'Y':'Υ',\n",
        "  'Z':'Ζ'\n",
        "}\n",
        "\n",
        "def obfuscate_char(ch: str) -> str:\n",
        "  mode = random.choices((\"plain\", \"leet\", \"homo\"), weights=(0.5, 0.4, 0.1))[0]\n",
        "  if mode == \"leet\" and ch in LEET:\n",
        "    return random.choice(LEET[ch])\n",
        "  if mode == \"homo\" and ch in HOMO:\n",
        "    return HOMO[ch]\n",
        "  return ch\n",
        "\n",
        "def render_patch(ch: str) -> Image.Image:\n",
        "  \"\"\"Return a 64×21 monochrome patch for a single (possibly obfuscated) char.\"\"\"\n",
        "  patch = Image.new(\"L\", (PATCH_W, IMG_H), color=255)\n",
        "  draw  = ImageDraw.Draw(patch)\n",
        "  draw.text((4, 4), obfuscate_char(ch), fill=0, font=FONT)\n",
        "  return patch\n",
        "\n",
        "def stitch_word(word: str, out_file: Path):\n",
        "  canvas = Image.new(\"L\", (IMG_W, IMG_H), color=255)\n",
        "  for idx, ch in enumerate(word):\n",
        "    glyph = render_patch(ch)\n",
        "    canvas.paste(glyph, (idx * PATCH_W, 0))\n",
        "  # light horizontal jitter\n",
        "  if random.random() < 0.3:\n",
        "    dx = random.randint(-2, 2)\n",
        "    canvas = canvas.transform(canvas.size, Image.AFFINE, (1, 0, dx, 0, 1, 0))\n",
        "  canvas.save(out_file)\n",
        "\n",
        "# wipe & rebuild train directory (safe for colab runs)\n",
        "if train_dir.exists():\n",
        "  shutil.rmtree(train_dir)\n",
        "train_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# generate every word (AAA … ZZZ)\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "all_words = [\"\".join(tpl) for tpl in itertools.product(alphabet, repeat=3)]\n",
        "\n",
        "for word in tqdm(all_words, desc=\"Generating train\"):\n",
        "  cls_dir = train_dir / word\n",
        "  cls_dir.mkdir(parents=True, exist_ok=True)\n",
        "  for k in range(N_VARIANTS):\n",
        "    stitch_word(word, cls_dir / f\"{word}_{k}.png\")\n",
        "\n",
        "print(\"✓ Training set complete.\")"
      ],
      "metadata": {
        "id": "-BRxWr1p--pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- Moves ~15 % of images from each class folder in train/ into a mirrored folder in test/\n",
        "- Guarantees at least ONE image stays in train/ (edge case handling)\n",
        "- Idempotent: skips any class that already has files in test/\n",
        "\"\"\"\n",
        "if not train_dir.exists():\n",
        "  raise SystemExit(\"✖ train/ does not exist – run build_words3_train.py first\")\n",
        "\n",
        "test_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for cls_dir in tqdm(list(train_dir.iterdir()), desc=\"Creating test split\"):\n",
        "  if not cls_dir.is_dir():\n",
        "    continue\n",
        "  tgt_cls = test_dir / cls_dir.name\n",
        "  tgt_cls.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # skip if we already moved files previously\n",
        "  if any(tgt_cls.iterdir()):\n",
        "    continue\n",
        "\n",
        "  imgs = list(cls_dir.glob(\"*.png\"))\n",
        "  n_move = max(1, math.floor(len(imgs) * FRACTION)) if len(imgs) > 1 else 0\n",
        "  random.shuffle(imgs)\n",
        "  for img in imgs[:n_move]:\n",
        "    shutil.move(img, tgt_cls / img.name)\n",
        "\n",
        "print(\"✓ Test split ready.\")\n",
        "print(\"Train images:\", sum(1 for _ in train_dir.rglob(\"*.png\")),\n",
        "      \"| Test images:\", sum(1 for _ in test_dir.rglob(\"*.png\")))"
      ],
      "metadata": {
        "id": "61fhBwTlANGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuumCMV4NETu"
      },
      "source": [
        "# **3. Load & Freeze the Single-Char Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.models.load_model(f\"{BASE_PATH}/char_cnn_ckpt_best.keras\")\n",
        "base_model.trainable = False # freeze weights initially\n",
        "print(\"Base model frozen — params:\", base_model.count_params())"
      ],
      "metadata": {
        "id": "HIhl-G41Wo7K",
        "outputId": "6c6b42fc-edbb-4a41-ee2c-edd128eefc79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model frozen — params: 2455450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc4cJg9cNkwe"
      },
      "source": [
        "# **4. Data Loading & Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SHAPE,\n",
        "  color_mode=\"grayscale\",\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42\n",
        ")\n",
        "\n",
        "# Val dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SHAPE,\n",
        "  color_mode=\"grayscale\",\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42\n",
        ")\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SHAPE,\n",
        "  color_mode=\"grayscale\",\n",
        "  shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "JJTNO9W2eOni",
        "outputId": "343aa246-3a7b-4f2f-ae28-63cf81fa7ba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 70304 files belonging to 17576 classes.\n",
            "Using 56244 files for training.\n",
            "Found 70304 files belonging to 17576 classes.\n",
            "Using 14060 files for validation.\n",
            "Found 17576 files belonging to 17576 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Visual Sanity Check**"
      ],
      "metadata": {
        "id": "6b3XnHPMxyen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility to display examples from each set\n",
        "def show_examples(ds, ds_name, num=5):\n",
        "  # Take one batch\n",
        "  for images, labels in ds.take(1):\n",
        "    images = images.numpy()\n",
        "    labels = labels.numpy()\n",
        "    class_names = ds.class_names\n",
        "    break\n",
        "\n",
        "  plt.figure(figsize=(6,6))\n",
        "  for i in range(num):\n",
        "    ax = plt.subplot(3, 3, i+1)\n",
        "    img = images[i].squeeze()  # shape: (H,W) since grayscale\n",
        "    lbl = class_names[labels[i].argmax()]\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"{ds_name}: {lbl}\")\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Display 5 examples from each split\n",
        "show_examples(train_ds, \"Train\")\n",
        "show_examples(val_ds, \"Val\")\n",
        "show_examples(test_ds, \"Test\")"
      ],
      "metadata": {
        "id": "CsR_L_nSsN_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4xIlbVLN-hN"
      },
      "source": [
        "# **6. Build the Sliding-Window Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVuQewrCOAhv"
      },
      "outputs": [],
      "source": [
        "def extract_patch(x, idx):\n",
        "  start = idx * PATCH_W\n",
        "  return x[:, :, start:start+PATCH_W, :] # (None, 64, 21, 1)\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_H, IMG_W, 1))\n",
        "logits = []\n",
        "\n",
        "for i in range(3):\n",
        "  patch = tf.keras.layers.Lambda(lambda z, i=i: extract_patch(z, i))(inputs)\n",
        "  patch = tf.keras.layers.Resizing(IMG_H, IMG_H)(patch) # -> (64 x 64 x 1)\n",
        "  # Re-use frozen base_model (shared weights)\n",
        "  logits.append(base_model(patch)) # (None, 26)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate()(logits) # (None, 78)\n",
        "# Hidden layer #1\n",
        "h1 = tf.keras.layers.Dense(256, activation='relu')(concat)\n",
        "h1 = tf.keras.layers.BatchNormalization()(h1)\n",
        "h1 = tf.keras.layers.Dropout(0.5)(h1)\n",
        "# Hidden layer #2\n",
        "h1 = tf.keras.layers.Dense(256, activation='relu')(h1)\n",
        "h1 = tf.keras.layers.Dropout(0.5)(h1)\n",
        "outputs = tf.keras.layers.Dense(EXPECTED_CLASSES, activation='softmax')(h1)\n",
        "word_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# (Optional: if accuracy is not great)\n",
        "# Freeze all weights except the last N blocks\n",
        "N = 1\n",
        "# Un-freeze last N layers of base_model\n",
        "for layer in base_model.layers[-N:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "# Compile model\n",
        "word_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "word_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVbhlvKOMjg"
      },
      "source": [
        "# **7. Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ifsAp6O1OOrx"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "  # 1. Checkpoint\n",
        "  ModelCheckpoint(CKPT_DIR, save_best_only=True, monitor='val_loss'),\n",
        "  # 2. Early stopping\n",
        "  EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
        "  # 3. Learning rate scheduler\n",
        "  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPi4tnFGOS4R"
      },
      "source": [
        "# **8. Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aai8C7KOVVh"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = word_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=20,\n",
        "  callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-compile with lower LR\n",
        "word_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "ft_history = word_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  initial_epoch=history.epoch[-1] + 1,\n",
        "  epochs=history.epoch[-1] + 5,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "yOKfnAj92MqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHMjuGLOOj5H"
      },
      "source": [
        "# **9. Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdfVNFw1OlRs"
      },
      "outputs": [],
      "source": [
        "word_model = tf.keras.models.load_model(CKPT_DIR) # best checkpoint\n",
        "test_loss, test_acc = word_model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Util for plotting confusion matrix\n",
        "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      cm (np.ndarray): square confusion matrix\n",
        "      class_names (List[str]): labels in the same order used to build cm\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(10, 9))\n",
        "  im = ax.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  ax.figure.colorbar(im, ax=ax, fraction=0.045)\n",
        "\n",
        "  # axes & ticks\n",
        "  ax.set(\n",
        "    xticks=np.arange(len(class_names)),\n",
        "    yticks=np.arange(len(class_names)),\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    ylabel=\"True label\",\n",
        "    xlabel=\"Predicted label\",\n",
        "    title=title,\n",
        "  )\n",
        "  plt.setp(ax.get_xticklabels(), rotation=90, ha=\"center\", va=\"center\")\n",
        "\n",
        "  # annotate cells\n",
        "  thresh = cm.max() / 2.0\n",
        "  for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "      ax.text(\n",
        "        j, i, format(cm[i, j], \"d\"),\n",
        "        ha=\"center\", va=\"center\",\n",
        "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "        fontsize=8\n",
        "      )\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Classification report\n",
        "y_pred, y_true = [], []\n",
        "for x, y in test_ds:\n",
        "  y_pred.extend(np.argmax(word_model.predict(x), axis=1))\n",
        "  y_true.extend(np.argmax(y.numpy(), axis=1))\n",
        "print(classification_report(y_true, y_pred, target_names=train_ds.class_names))\n",
        "\n",
        "# Confusion matrix heat-map (optional)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, train_ds.class_names, title=\"3-Letter Word Confusion Matrix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeZuj2jpOrqf"
      },
      "source": [
        "# **10. Qualitative Error Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSwpu5vjOuEs"
      },
      "outputs": [],
      "source": [
        "# Plot a few misclassified 3-letter words\n",
        "mis_idx = [i for i,(t,p) in enumerate(zip(y_true, y_pred)) if t != p]\n",
        "show_examples(test_ds.unbatch().skip(mis_idx[0]), \"Misclassified example\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyMYpdwVYB5hwoi6+8IEwXZC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-amy/project-codebase/blob/main/Word_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNvi5n0bLCda"
      },
      "source": [
        "# **CNN Sliding-Window Model for 3-Letter Word De-Obfuscation**\n",
        "Stage 2 of MSc Project — Ashraf Muhammed Yusuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3t0wN17LOBf"
      },
      "source": [
        "# **1. Colab Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3XkX4M9gxev"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UUMBUoObLUnb"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import os, sys, random, itertools, pathlib, math, shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from tensorflow.keras import mixed_precision\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import defaultdict\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91L4Z6naS9gN"
      },
      "outputs": [],
      "source": [
        "# 1.3 Mount Drive & define base path\n",
        "# Mount Drive so you can read datasets and write checkpoints\n",
        "# Link to Drive:\n",
        "# https://drive.google.com/drive/folders/1sfNG1PkmTPBe1wOSQXZmfdkvR97Hn9lk?usp=sharing\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiuZCz5QZ-mr"
      },
      "source": [
        "# **2. Data Generation**\n",
        "This block generates the 'three-letter words' dataset afresh if you do not already have it (You can access it here: https://drive.google.com/drive/folders/1kygA17GiCeCs8qTeDBEndU6TkXnEu-m7?usp=drive_link). It synthesizes three three-letter words from the character dataset (https://drive.google.com/drive/folders/1eUaTNW8zVjTArg0JszbCdCEq0tTdx89n?usp=drive_link)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KgzKPaWRcDTn"
      },
      "outputs": [],
      "source": [
        "# paths & constants\n",
        "BASE_PATH = Path(\"/content/drive/MyDrive/MScProject\")\n",
        "GLYPH_DIR = Path(f\"{BASE_PATH}/data/characters/train\")\n",
        "DATA_ROOT = Path(f\"{BASE_PATH}/data/words3\")\n",
        "CKPT_DIR = f\"{BASE_PATH}/words3_ckpt_best.keras\"\n",
        "BATCH = 128\n",
        "IMG_H = IMG_W = 64\n",
        "IMG_SHAPE = (IMG_H, IMG_W)\n",
        "PATCH_W = IMG_W // 3\n",
        "VARIANTS_PER = 5 # per word\n",
        "EXPECTED_CLASSES = 26**3 # 26³ = 17,576\n",
        "FINAL_TEST_FRAC = 0.20\n",
        "SEED = 42\n",
        "PATCH_W = IMG_W // 3 # 21 when IMG_W = 64\n",
        "N_VARIANTS = 4 # number of images per class\n",
        "FRACTION = 0.15 # 15 %\n",
        "train_dir = DATA_ROOT / \"train\"\n",
        "test_dir  = DATA_ROOT / \"test\"\n",
        "\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- Generates a single ‘train/’ directory with 17 576 class folders (AAA … ZZZ)\n",
        "- Each class contains N_VARIANTS PNG images rendered on-the-fly (no external glyph reuse)\n",
        "- Obfuscation applied per-character (leet + homoglyph + random spacing jitter)\n",
        "- Idempotent: if the train folder already has 17 576 classes it exits immediately\n",
        "\"\"\"\n",
        "\n",
        "# Define font\n",
        "try:\n",
        "  FONT_PATH = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "  FONT = ImageFont.truetype(FONT_PATH, 40)\n",
        "except (IOError, OSError):\n",
        "  print(\"DejaVuSans not found; using PIL default bitmap font.\")\n",
        "  FONT = ImageFont.load_default()\n",
        "\n",
        "# fast-exit guard\n",
        "if train_dir.exists() and len([p for p in train_dir.iterdir() if p.is_dir()]) == EXPECTED_CLASSES:\n",
        "  print(\"words3/train already complete – nothing to do.\")\n",
        "  sys.exit(0)\n",
        "\n",
        "# mapping tables (uppercase only)\n",
        "LEET = {\n",
        "  'A': ['Α', '4', 'Д', 'Ä', 'Á', 'À', 'Â', '@', 'Δ'],\n",
        "  'B': ['8', 'β', 'Β', 'В'],\n",
        "  'C': ['Ç', 'Ć', 'Č', 'С'],\n",
        "  'D': ['Ð', 'Ď'],\n",
        "  'E': ['3', 'Σ', 'Έ', 'Ε', 'Е', 'Ë', 'É', 'È', 'Ê'],\n",
        "  'F': ['Φ', 'Ƒ'],\n",
        "  'G': ['6', 'Ğ', 'Ģ', 'Γ'],\n",
        "  'H': ['Η', 'Н'],\n",
        "  'I': ['1', '|', 'Í', 'Ì', 'Î', 'Ï', 'И'],\n",
        "  'J': ['Ј'],\n",
        "  'K': ['Κ', 'К'],\n",
        "  'L': ['Ι', 'Ł', 'Ĺ', 'Л'],\n",
        "  'M': ['Μ', 'М'],\n",
        "  'N': ['Ν', 'Ń', 'Ñ', 'Н'],\n",
        "  'O': ['0', 'Θ', 'Ο', 'Ө', 'Ø', 'Ö', 'Ó', 'Ò', 'Ô'],\n",
        "  'P': ['Ρ', 'Р'],\n",
        "  'Q': ['Φ'],\n",
        "  'R': ['®', 'Я', 'Ř', 'Ŕ'],\n",
        "  'S': ['5', '$', 'Ѕ', 'Ś', 'Š'],\n",
        "  'T': ['Τ', 'Т'],\n",
        "  'U': ['Υ', 'Ц', 'Ü', 'Ú', 'Ù', 'Û'],\n",
        "  'V': ['Ѵ', 'V'],\n",
        "  'W': ['Ω', 'Ѡ', 'Ψ', 'Ш', 'Щ'],\n",
        "  'X': ['Χ', 'Ж', 'Х'],\n",
        "  'Y': ['Υ', 'Ү', 'Ý', 'Ÿ'],\n",
        "  'Z': ['Ζ', 'Ż', 'Ź', 'Ž', 'З', '2']\n",
        "}\n",
        "HOMO = {\n",
        "  'A':'Α',\n",
        "  'B':'Β',\n",
        "  'C':'С',\n",
        "  'E':'Ε',\n",
        "  'H':'Н',\n",
        "  'K':'Κ',\n",
        "  'M':'Μ',\n",
        "  'O':'О',\n",
        "  'P':'Р',\n",
        "  'T':'Τ',\n",
        "  'X':'Χ',\n",
        "  'Y':'Υ',\n",
        "  'Z':'Ζ'\n",
        "}\n",
        "\n",
        "def obfuscate_char(ch: str) -> str:\n",
        "  mode = random.choices((\"plain\", \"leet\", \"homo\"), weights=(0.5, 0.4, 0.1))[0]\n",
        "  if mode == \"leet\" and ch in LEET:\n",
        "    return random.choice(LEET[ch])\n",
        "  if mode == \"homo\" and ch in HOMO:\n",
        "    return HOMO[ch]\n",
        "  return ch\n",
        "\n",
        "def render_patch(ch: str) -> Image.Image:\n",
        "  \"\"\"Return a 64×21 monochrome patch for a single (possibly obfuscated) char.\"\"\"\n",
        "  patch = Image.new(\"L\", (PATCH_W, IMG_H), color=255)\n",
        "  draw  = ImageDraw.Draw(patch)\n",
        "  draw.text((4, 4), obfuscate_char(ch), fill=0, font=FONT)\n",
        "  return patch\n",
        "\n",
        "def stitch_word(word: str, out_file: Path):\n",
        "  canvas = Image.new(\"L\", (IMG_W, IMG_H), color=255)\n",
        "  for idx, ch in enumerate(word):\n",
        "    glyph = render_patch(ch)\n",
        "    canvas.paste(glyph, (idx * PATCH_W, 0))\n",
        "  # light horizontal jitter\n",
        "  if random.random() < 0.3:\n",
        "    dx = random.randint(-2, 2)\n",
        "    canvas = canvas.transform(canvas.size, Image.AFFINE, (1, 0, dx, 0, 1, 0))\n",
        "  canvas.save(out_file)\n",
        "\n",
        "# wipe & rebuild train directory (safe for colab runs)\n",
        "if train_dir.exists():\n",
        "  shutil.rmtree(train_dir)\n",
        "train_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# generate every word (AAA … ZZZ)\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "all_words = [\"\".join(tpl) for tpl in itertools.product(alphabet, repeat=3)]\n",
        "\n",
        "for word in tqdm(all_words, desc=\"Generating train\"):\n",
        "  cls_dir = train_dir / word\n",
        "  cls_dir.mkdir(parents=True, exist_ok=True)\n",
        "  for k in range(N_VARIANTS):\n",
        "    stitch_word(word, cls_dir / f\"{word}_{k}.png\")\n",
        "\n",
        "print(\"✓ Training set complete.\")"
      ],
      "metadata": {
        "id": "-BRxWr1p--pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- Make a permanent 15 % test split on Drive\n",
        "- Assumes you have a single words3/train/AAA … ZZZ/*.png structure already.\n",
        "- Creates /words3/test/AAA … ZZZ/ and MOVES files (no duplication).\n",
        "- Safe to rerun – will skip classes already processed.\n",
        "\"\"\"\n",
        "\n",
        "# fast-guard: already split?\n",
        "if test_dir.exists() and len([d for d in test_dir.iterdir() if d.is_dir()]) == EXPECTED_CLASSES:\n",
        "  print(\"words3/test already holds all\", EXPECTED_CLASSES, \"class folders – nothing to do.\")\n",
        "  sys.exit(0)\n",
        "\n",
        "test_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# split loop\n",
        "for cls_dir in tqdm.tqdm([d for d in train_dir.iterdir() if d.is_dir()], desc=\"Creating 15 % test split\"):\n",
        "  tgt_cls = test_dir / cls_dir.name\n",
        "  tgt_cls.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # list PNGs still in train/ for this class (those already moved last run are gone)\n",
        "  imgs = list(cls_dir.glob(\"*.png\"))\n",
        "  if not imgs: # all imgs already moved in a previous run\n",
        "    continue\n",
        "\n",
        "  # number to move: 15 % rounded down, but keep ≥1 in train/\n",
        "  n_move = max(1, math.floor(len(imgs) * FRACTION))\n",
        "  n_move = min(n_move, len(imgs) - 1)          # safeguard: leave ≥1\n",
        "\n",
        "  random.shuffle(imgs)\n",
        "  for img in imgs[:n_move]:\n",
        "    shutil.move(str(img), tgt_cls / img.name)\n",
        "\n",
        "print(\"Test split ready.\")\n",
        "print(\"Train images:\", sum(1 for _ in train_dir.rglob(\"*.png\")))\n",
        "print(\"Test images:\", sum(1 for _ in test_dir.rglob(\"*.png\")))"
      ],
      "metadata": {
        "id": "61fhBwTlANGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuumCMV4NETu"
      },
      "source": [
        "# **3. Load & Freeze the Single-Char Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.models.load_model(f\"{BASE_PATH}/char_cnn_ckpt_best.keras\")\n",
        "base_model.trainable = False # freeze weights initially\n",
        "print(\"Base model frozen — params:\", base_model.count_params())"
      ],
      "metadata": {
        "id": "HIhl-G41Wo7K",
        "outputId": "9828839d-f63d-4e6a-ed5e-3ab66902cc39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model frozen — params: 2455450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc4cJg9cNkwe"
      },
      "source": [
        "# **4. Data Loading & Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SHAPE,\n",
        "  color_mode=\"grayscale\",\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42\n",
        ")\n",
        "\n",
        "# Val dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SHAPE,\n",
        "  color_mode=\"grayscale\",\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42\n",
        ")\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SHAPE,\n",
        "  color_mode=\"grayscale\",\n",
        "  shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "JJTNO9W2eOni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Visual Sanity Check**"
      ],
      "metadata": {
        "id": "6b3XnHPMxyen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility to display examples from each set\n",
        "def show_examples(ds, ds_name, num=5):\n",
        "  # Take one batch\n",
        "  for images, labels in ds.take(1):\n",
        "    images = images.numpy()\n",
        "    labels = labels.numpy()\n",
        "    class_names = ds.class_names\n",
        "    break\n",
        "\n",
        "  plt.figure(figsize=(6,6))\n",
        "  for i in range(num):\n",
        "    ax = plt.subplot(3, 3, i+1)\n",
        "    img = images[i].squeeze()  # shape: (H,W) since grayscale\n",
        "    lbl = class_names[labels[i].argmax()]\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"{ds_name}: {lbl}\")\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Display 5 examples from each split\n",
        "show_examples(train_ds, \"Train\")\n",
        "show_examples(val_ds, \"Val\")\n",
        "show_examples(test_ds, \"Test\")"
      ],
      "metadata": {
        "id": "CsR_L_nSsN_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4xIlbVLN-hN"
      },
      "source": [
        "# **6. Build the Sliding-Window Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVuQewrCOAhv"
      },
      "outputs": [],
      "source": [
        "def extract_patch(x, idx):\n",
        "  start = idx * PATCH_W\n",
        "  return x[:, :, start:start+PATCH_W, :] # (None, 64, 21, 1)\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_H, IMG_W, 1))\n",
        "logits = []\n",
        "\n",
        "for i in range(3):\n",
        "  patch = tf.keras.layers.Lambda(lambda z, i=i: extract_patch(z, i))(inputs)\n",
        "  patch = tf.keras.layers.Resizing(IMG_H, IMG_H)(patch) # -> (64 x 64 x 1)\n",
        "  # Re-use frozen base_model (shared weights)\n",
        "  logits.append(base_model(patch)) # (None, 26)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate()(logits) # (None, 78)\n",
        "# Hidden layer #1\n",
        "h1 = tf.keras.layers.Dense(256, activation='relu')(concat)\n",
        "h1 = tf.keras.layers.BatchNormalization()(h1)\n",
        "h1 = tf.keras.layers.Dropout(0.5)(h1)\n",
        "# Hidden layer #2\n",
        "h1 = tf.keras.layers.Dense(256, activation='relu')(h1)\n",
        "h1 = tf.keras.layers.Dropout(0.5)(h1)\n",
        "outputs = tf.keras.layers.Dense(EXPECTED_CLASSES, activation='softmax')(h1)\n",
        "word_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# (Optional: if accuracy is not great)\n",
        "# Freeze all weights except the last N blocks\n",
        "N = 1\n",
        "# Un-freeze last N layers of base_model\n",
        "for layer in base_model.layers[-N:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "# Compile model\n",
        "word_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "word_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVbhlvKOMjg"
      },
      "source": [
        "# **7. Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifsAp6O1OOrx"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "  # 1. Checkpoint\n",
        "  ModelCheckpoint(CKPT_DIR, save_best_only=True, monitor='val_loss'),\n",
        "  # 2. Early stopping\n",
        "  EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
        "  # 3. Learning rate scheduler\n",
        "  ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPi4tnFGOS4R"
      },
      "source": [
        "# **8. Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aai8C7KOVVh"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = word_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=20,\n",
        "  callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-compile with lower LR\n",
        "word_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "ft_history = word_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  initial_epoch=history.epoch[-1] + 1,\n",
        "  epochs=history.epoch[-1] + 5,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "yOKfnAj92MqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHMjuGLOOj5H"
      },
      "source": [
        "# **9. Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdfVNFw1OlRs"
      },
      "outputs": [],
      "source": [
        "word_model = tf.keras.models.load_model(CKPT_DIR) # best checkpoint\n",
        "test_loss, test_acc = word_model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Util for plotting confusion matrix\n",
        "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\"):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "      cm (np.ndarray): square confusion matrix\n",
        "      class_names (List[str]): labels in the same order used to build cm\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(figsize=(10, 9))\n",
        "  im = ax.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
        "  ax.figure.colorbar(im, ax=ax, fraction=0.045)\n",
        "\n",
        "  # axes & ticks\n",
        "  ax.set(\n",
        "    xticks=np.arange(len(class_names)),\n",
        "    yticks=np.arange(len(class_names)),\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    ylabel=\"True label\",\n",
        "    xlabel=\"Predicted label\",\n",
        "    title=title,\n",
        "  )\n",
        "  plt.setp(ax.get_xticklabels(), rotation=90, ha=\"center\", va=\"center\")\n",
        "\n",
        "  # annotate cells\n",
        "  thresh = cm.max() / 2.0\n",
        "  for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "      ax.text(\n",
        "        j, i, format(cm[i, j], \"d\"),\n",
        "        ha=\"center\", va=\"center\",\n",
        "        color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "        fontsize=8\n",
        "      )\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Classification report\n",
        "y_pred, y_true = [], []\n",
        "for x, y in test_ds:\n",
        "  y_pred.extend(np.argmax(word_model.predict(x), axis=1))\n",
        "  y_true.extend(np.argmax(y.numpy(), axis=1))\n",
        "print(classification_report(y_true, y_pred, target_names=train_ds.class_names))\n",
        "\n",
        "# Confusion matrix heat-map (optional)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, train_ds.class_names, title=\"3-Letter Word Confusion Matrix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeZuj2jpOrqf"
      },
      "source": [
        "# **10. Qualitative Error Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSwpu5vjOuEs"
      },
      "outputs": [],
      "source": [
        "# Plot a few misclassified 3-letter words\n",
        "mis_idx = [i for i,(t,p) in enumerate(zip(y_true, y_pred)) if t != p]\n",
        "show_examples(test_ds.unbatch().skip(mis_idx[0]), \"Misclassified example\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyNXKmRjuypZduWymn93GHXU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNvi5n0bLCda"
      },
      "source": [
        "# **CNN Sliding-Window Model for 3-Letter Word De-Obfuscation**\n",
        "Stage 2 of MSc Project — Ashraf Muhammed Yusuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3t0wN17LOBf"
      },
      "source": [
        "# **1. Colab Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3XkX4M9gxev"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional - Install font (we will use it to generate images)\n",
        "# Colab / Ubuntu repositories already ship Roboto\n",
        "!sudo apt-get -qq update\n",
        "!sudo apt-get -qq install fonts-roboto"
      ],
      "metadata": {
        "id": "3DrSvqCfIfbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUMBUoObLUnb"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import os, sys, random, itertools, pathlib, math, shutil, io, requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tqdm as tq\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers, models, mixed_precision\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import defaultdict\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91L4Z6naS9gN"
      },
      "outputs": [],
      "source": [
        "# 1.3 Mount Drive & define base path\n",
        "# Mount Drive so you can read datasets and write checkpoints\n",
        "# Link to Drive:\n",
        "# https://drive.google.com/drive/folders/1sfNG1PkmTPBe1wOSQXZmfdkvR97Hn9lk?usp=sharing\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiuZCz5QZ-mr"
      },
      "source": [
        "# **2. Constants & Data Generation**\n",
        "This block generates the 'three-letter words' dataset afresh if you do not already have it (You can access it here: https://drive.google.com/drive/folders/1kygA17GiCeCs8qTeDBEndU6TkXnEu-m7?usp=drive_link). It synthesizes three three-letter words from the character dataset (https://drive.google.com/drive/folders/1eUaTNW8zVjTArg0JszbCdCEq0tTdx89n?usp=drive_link)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgzKPaWRcDTn"
      },
      "outputs": [],
      "source": [
        "# paths & constants\n",
        "BASE_PATH = Path(\"/content/drive/MyDrive/MScProject\")\n",
        "GLYPH_DIR = Path(f\"{BASE_PATH}/data/characters/train\")\n",
        "DATA_ROOT = Path(f\"{BASE_PATH}/data/words3\")\n",
        "CKPT_DIR = f\"{BASE_PATH}/words3_ckpt_best.keras\"\n",
        "BATCH = 64\n",
        "IMG_H = IMG_W = 64\n",
        "IMG_SHAPE = (IMG_H, IMG_W)\n",
        "PATCH_W = IMG_W // 3\n",
        "VARIANTS_PER = 5 # per word\n",
        "EXPECTED_CLASSES = 26**3 # 26³ = 17,576\n",
        "FINAL_TEST_FRAC = 0.20\n",
        "SEED = 42\n",
        "PATCH_W = IMG_W // 3 # 21 when IMG_W = 64\n",
        "N_VARIANTS = 4 # number of images per class\n",
        "FRACTION = 0.15 # 15 %\n",
        "train_dir = DATA_ROOT / \"train\"\n",
        "test_dir  = DATA_ROOT / \"test\"\n",
        "\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- Generates a single ‘train/’ directory with 17,576 class folders (AAA … ZZZ)\n",
        "- Each class contains N_VARIANTS PNG images rendered on-the-fly (no external glyph reuse)\n",
        "- Obfuscation applied per-character (leet + random spacing jitter)\n",
        "- Idempotent: if the train folder already has 17,576 classes it exits immediately\n",
        "\"\"\"\n",
        "\n",
        "def obfuscate_char(ch: str) -> str:\n",
        "    mode = random.choices((\"plain\", \"leet\"), weights=(0.5, 0.4, 0.1))[0]\n",
        "    if mode == \"leet\" and ch in LEET:\n",
        "        return random.choice(LEET[ch])\n",
        "    return ch\n",
        "\n",
        "def render_patch(ch: str) -> Image.Image:\n",
        "    # Return a 64×21 monochrome patch for a single (possibly obfuscated) char\n",
        "    patch = Image.new(\"L\", (PATCH_W, IMG_H), color=255)\n",
        "    draw  = ImageDraw.Draw(patch)\n",
        "    draw.text((4, 4), obfuscate_char(ch), fill=0, font=FONT)\n",
        "    return patch\n",
        "\n",
        "def stitch_word(word: str, out_file: Path):\n",
        "  canvas = Image.new(\"L\", (IMG_W, IMG_H), color=255)\n",
        "\n",
        "  for idx, ch in enumerate(word):\n",
        "      glyph = render_patch(ch)\n",
        "      canvas.paste(glyph, (idx * PATCH_W, 0))\n",
        "  # light horizontal jitter\n",
        "  if random.random() < 0.3:\n",
        "      dx = random.randint(-2, 2)\n",
        "      canvas = canvas.transform(canvas.size, Image.AFFINE, (1, 0, dx, 0, 1, 0))\n",
        "\n",
        "  canvas.save(out_file)\n",
        "\n",
        "AAA = train_dir / \"AAA\"\n",
        "dataset_ready = AAA.is_dir() and any(AAA.glob(\"*.png\"))\n",
        "\n",
        "if dataset_ready:\n",
        "    print(\"words3/train already complete – nothing to do.\")\n",
        "else:\n",
        "    # Define font\n",
        "    try:\n",
        "        FONT_PATH = \"/usr/share/fonts/truetype/roboto/Roboto-Medium.ttf\"\n",
        "        # A big font size makes the letters cut-off at the edges\n",
        "        # when we slice through the images,\n",
        "        # mimicking real-world scenarios where this operation\n",
        "        # may not produce clean cuts of letters\n",
        "        FONT_SIZE = 40\n",
        "        FONT = ImageFont.truetype(FONT_PATH, FONT_SIZE)\n",
        "        print(\"Using Roboto Medium font to generate images\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading font: {e}\")\n",
        "        print(\"Using default font to generate images\")\n",
        "        FONT = ImageFont.load_default()\n",
        "\n",
        "  # mapping tables (uppercase only)\n",
        "  LEET = {\n",
        "    'A': ['Α', '4', 'Д', 'Ä', 'Á', 'À', 'Â', '@', 'Δ'],\n",
        "    'B': ['8', 'β', 'Β', 'В'],\n",
        "    'C': ['Ç', 'Ć', 'Č', 'С'],\n",
        "    'D': ['Ð', 'Ď'],\n",
        "    'E': ['3', 'Σ', 'Έ', 'Ε', 'Е', 'Ë', 'É', 'È', 'Ê'],\n",
        "    'F': ['Φ', 'Ƒ'],\n",
        "    'G': ['6', 'Ğ', 'Ģ', 'Γ'],\n",
        "    'H': ['Η', 'Н'],\n",
        "    'I': ['1', '|', 'Í', 'Ì', 'Î', 'Ï', 'И'],\n",
        "    'J': ['Ј'],\n",
        "    'K': ['Κ', 'К'],\n",
        "    'L': ['Ι', 'Ł', 'Ĺ', 'Л'],\n",
        "    'M': ['Μ', 'М'],\n",
        "    'N': ['Ν', 'Ń', 'Ñ', 'Н'],\n",
        "    'O': ['0', 'Θ', 'Ο', 'Ө', 'Ø', 'Ö', 'Ó', 'Ò', 'Ô'],\n",
        "    'P': ['Ρ', 'Р'],\n",
        "    'Q': ['Φ'],\n",
        "    'R': ['®', 'Я', 'Ř', 'Ŕ'],\n",
        "    'S': ['5', '$', 'Ѕ', 'Ś', 'Š'],\n",
        "    'T': ['Τ', 'Т'],\n",
        "    'U': ['Υ', 'Ц', 'Ü', 'Ú', 'Ù', 'Û'],\n",
        "    'V': ['Ѵ', 'V'],\n",
        "    'W': ['Ω', 'Ѡ', 'Ψ', 'Ш', 'Щ'],\n",
        "    'X': ['Χ', 'Ж', 'Х'],\n",
        "    'Y': ['Υ', 'Ү', 'Ý', 'Ÿ'],\n",
        "    'Z': ['Ζ', 'Ż', 'Ź', 'Ž', 'З', '2']\n",
        "  }\n",
        "\n",
        "  # wipe & rebuild train directory (safe for colab runs)\n",
        "  if train_dir.exists():\n",
        "      shutil.rmtree(train_dir)\n",
        "\n",
        "  train_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # generate every word (AAA … ZZZ)\n",
        "  alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "  all_words = [\"\".join(tpl) for tpl in itertools.product(alphabet, repeat=3)]\n",
        "\n",
        "  for word in tqdm(all_words, desc=\"Generating train\"):\n",
        "      cls_dir = train_dir / word\n",
        "      cls_dir.mkdir(parents=True, exist_ok=True)\n",
        "      for k in range(N_VARIANTS):\n",
        "          stitch_word(word, cls_dir / f\"{word}_{k}.png\")\n",
        "\n",
        "  print(\"Training set complete.\")"
      ],
      "metadata": {
        "id": "-BRxWr1p--pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- Make a permanent 15% test split on Drive\n",
        "- Assumes you have a single words3/train/AAA … ZZZ/*.png structure already.\n",
        "- Creates /words3/test/AAA … ZZZ/ and MOVES files (no duplication).\n",
        "- Safe to rerun – will skip classes already processed.\n",
        "\"\"\"\n",
        "import tqdm\n",
        "\n",
        "AAA = test_dir / \"AAA\"\n",
        "dataset_ready = AAA.is_dir() and any(AAA.glob(\"*.png\"))\n",
        "\n",
        "if dataset_ready:\n",
        "    print(\"words3/test already complete – nothing to do.\")\n",
        "else:\n",
        "    test_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # split loop\n",
        "  for cls_dir in tqdm.tqdm([d for d in train_dir.iterdir() if d.is_dir()], desc=\"Creating 15 % test split\"):\n",
        "      tgt_cls = test_dir / cls_dir.name\n",
        "      tgt_cls.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # list PNGs still in train/ for this class (those already moved last run are gone)\n",
        "    imgs = list(cls_dir.glob(\"*.png\"))\n",
        "    if not imgs: # all imgs already moved in a previous run\n",
        "        continue\n",
        "\n",
        "    # number to move: 15% rounded down, but keep ≥1 in train/\n",
        "    n_move = max(1, math.floor(len(imgs) * FRACTION))\n",
        "    n_move = min(n_move, len(imgs) - 1) # safeguard: leave ≥1\n",
        "\n",
        "    random.shuffle(imgs)\n",
        "    for img in imgs[:n_move]:\n",
        "        shutil.move(str(img), tgt_cls / img.name)\n",
        "\n",
        "  print(\"Test split ready.\")\n",
        "  print(\"Train images:\", sum(1 for _ in train_dir.rglob(\"*.png\")))\n",
        "  print(\"Test images:\", sum(1 for _ in test_dir.rglob(\"*.png\")))"
      ],
      "metadata": {
        "id": "61fhBwTlANGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc4cJg9cNkwe"
      },
      "source": [
        "# **3. Dataset Loading & Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalise(img, label):\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=BATCH,\n",
        "    image_size=IMG_SHAPE,\n",
        "    color_mode=\"grayscale\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Val dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=BATCH,\n",
        "    image_size=IMG_SHAPE,\n",
        "    color_mode=\"grayscale\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=BATCH,\n",
        "    image_size=IMG_SHAPE,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Generate class names for future reference\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "# Preprocess datasets\n",
        "train_ds = (train_ds\n",
        "            .map(normalise, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .apply(tf.data.experimental.ignore_errors())\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "val_ds = (val_ds\n",
        "          .map(normalise, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "          .apply(tf.data.experimental.ignore_errors())\n",
        "          .prefetch(tf.data.AUTOTUNE))\n",
        "test_ds = (test_ds\n",
        "           .map(normalise, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "           .apply(tf.data.experimental.ignore_errors())\n",
        "           .prefetch(tf.data.AUTOTUNE))"
      ],
      "metadata": {
        "id": "JJTNO9W2eOni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Visual Sanity Check**"
      ],
      "metadata": {
        "id": "6b3XnHPMxyen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility to display examples from each set\n",
        "def show_examples(ds, ds_name, num=5):\n",
        "  # Take one batch\n",
        "  for images, labels in ds.take(1):\n",
        "      images = images.numpy()\n",
        "      labels = labels.numpy()\n",
        "      break\n",
        "\n",
        "  plt.figure(figsize=(6,6))\n",
        "\n",
        "  for i in range(num):\n",
        "      ax = plt.subplot(3, 3, i+1)\n",
        "      img = images[i].squeeze()  # shape: (H,W) since grayscale\n",
        "      lbl = class_names[labels[i].argmax()]\n",
        "      plt.imshow(img, cmap='gray')\n",
        "      plt.title(f\"{ds_name}: {lbl}\")\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Display 5 examples from each split\n",
        "show_examples(train_ds, \"Train\")\n",
        "show_examples(val_ds, \"Val\")\n",
        "show_examples(test_ds, \"Test\")"
      ],
      "metadata": {
        "id": "CsR_L_nSsN_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuumCMV4NETu"
      },
      "source": [
        "# **5. Load & Freeze the Single-Char Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.models.load_model(f\"{BASE_PATH}/char_cnn_ckpt_best.keras\")\n",
        "base_model.trainable = False # freeze weights initially\n",
        "print(\"Base model frozen — params:\", base_model.count_params())"
      ],
      "metadata": {
        "id": "HIhl-G41Wo7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. (Optional) Unfreeze last N Conv Blocks before Training**\n",
        "If accuracy was low in the last training run, you should try unfreezing the last conv blocks of the base (character) model before running training again."
      ],
      "metadata": {
        "id": "wXXbBkr8l5dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unfreeze_last_conv_blocks(base_model, N=1):\n",
        "    \"\"\"\n",
        "    Set `trainable=True` for the last N Conv2D layers (+ their following\n",
        "    BatchNorm, ReLU, etc. if present) in `base_model`.  All earlier layers\n",
        "    remain frozen.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    base_model : tf.keras.Model\n",
        "        The pretrained character-classifier model.\n",
        "    N : int\n",
        "        How many of the deepest Conv2D layers (counted from the output side)\n",
        "        to unfreeze.\n",
        "    \"\"\"\n",
        "    # 1) Freeze everything first\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # 2) Collect indices of all Conv2D layers\n",
        "    conv_idx = [idx for idx, layer in enumerate(base_model.layers)\n",
        "                if isinstance(layer, tf.keras.layers.Conv2D)]\n",
        "\n",
        "    # 3) Decide which indices to unfreeze (last N)\n",
        "    if N > len(conv_idx):\n",
        "        raise ValueError(f\"Model only has {len(conv_idx)} Conv2D layers, \"\n",
        "                         f\"cannot unfreeze {N}\")\n",
        "\n",
        "    to_unfreeze = conv_idx[-N:]\n",
        "\n",
        "    # 4) Unfreeze selected Conv2D layers *and* everything that follows them\n",
        "    #    (so the gradient flows through BN / ReLU / Dense that depend on them)\n",
        "    for idx in to_unfreeze:\n",
        "        for layer in base_model.layers[idx:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    print(f\"Unfroze {N} Conv2D block(s) starting with layer(s):\",\n",
        "          [base_model.layers[i].name for i in to_unfreeze])\n",
        "\n",
        "# Unfreeze last N conv blocks\n",
        "unfreeze_last_conv_blocks(base_model, N=1)"
      ],
      "metadata": {
        "id": "MKr5M5sm8pDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4xIlbVLN-hN"
      },
      "source": [
        "# **7. Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVuQewrCOAhv"
      },
      "outputs": [],
      "source": [
        "def extract_patch(x, idx):\n",
        "    start = idx * PATCH_W\n",
        "    return x[:, :, start:start+PATCH_W, :] # (None, 64, 21, 1)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_H, IMG_W, 1))\n",
        "logits = []\n",
        "\n",
        "for i in range(3):\n",
        "    patch = layers.Lambda(lambda z, i=i: extract_patch(z, i))(inputs)\n",
        "    patch = layers.Resizing(IMG_H, IMG_H)(patch) # -> (64 x 64 x 1)\n",
        "    # Re-use frozen base_model (shared weights)\n",
        "    logits.append(base_model(patch)) # (None, 26)\n",
        "\n",
        "concat = layers.Concatenate()(logits) # (None, 78)\n",
        "\n",
        "# FC + ReLU\n",
        "x = layers.Dense(256, activation='relu')(concat)\n",
        "\n",
        "# Dropout Regularisation\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Output\n",
        "outputs = layers.Dense(EXPECTED_CLASSES, activation='softmax')(x)\n",
        "\n",
        "# Create model & print summary\n",
        "model = models.Model(inputs, outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVbhlvKOMjg"
      },
      "source": [
        "# **8. Compilation & Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifsAp6O1OOrx"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "# 1. Checkpoint\n",
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    CKPT_DIR,\n",
        "    save_best_only=True, # keep only the best model\n",
        "    monitor='val_loss'\n",
        ")\n",
        "\n",
        "# 2. Early stopping\n",
        "es = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5, # stop ~5 epochs after val_loss stalls\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 3. LR Scheduler\n",
        "lr_s = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "cb = [ckpt, es, lr_s]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPi4tnFGOS4R"
      },
      "source": [
        "# **9. Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aai8C7KOVVh"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=30,\n",
        "  callbacks=cb\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHMjuGLOOj5H"
      },
      "source": [
        "# **10. Evaluation & Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best checkpoint's weights\n",
        "model.load_weights(CKPT_DIR)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Gather all ground-truths and predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for batch_x, batch_y in test_ds:\n",
        "  preds = model.predict(batch_x)\n",
        "  y_pred.extend(np.argmax(preds, axis=1))\n",
        "  y_true.extend(np.argmax(batch_y.numpy(), axis=1))\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=90)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Training curves\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, history.history['accuracy'],    label='train_acc')\n",
        "plt.plot(epochs, history.history['val_accuracy'],label='val_acc')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, history.history['loss'],    label='train_loss')\n",
        "plt.plot(epochs, history.history['val_loss'],label='val_loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "RhqpDJr7Rvjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeZuj2jpOrqf"
      },
      "source": [
        "# **11. Qualitative Error Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a few misclassified 3-letter words\n",
        "\n",
        "# flatten to individual examples\n",
        "flat_ds = test_ds.unbatch()\n",
        "\n",
        "# find the first misclassified index\n",
        "idx = mis_idx[0]\n",
        "\n",
        "# grab exactly one element at position idx\n",
        "for i, (img, label) in enumerate(flat_ds):\n",
        "    if i == idx:\n",
        "        true_class = train_ds.class_names[y_true[idx]]\n",
        "        pred_class = train_ds.class_names[y_pred[idx]]\n",
        "        # now call your plotting function (or inline matplotlib)\n",
        "        plt.figure(figsize=(2,2))\n",
        "        plt.imshow(img[...,0], cmap=\"gray\")\n",
        "        plt.title(f\"True: {true_class}\\nPred: {pred_class}\")\n",
        "        plt.axis(\"off\")\n",
        "        break"
      ],
      "metadata": {
        "id": "EADfPJpMRyAT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyNRjrkA6E8zy5WLuFtKwf/c"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
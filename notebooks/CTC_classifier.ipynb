{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMW4wh4rcSztNbrDez2IWNM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Model for Character De-Obfuscation**\n",
        "Stage 3 of MSc Project — Ashraf Muhammed Yusuf"
      ],
      "metadata": {
        "id": "tG2PdS0_kbJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Colab Environment Setup** - Imports & Constants"
      ],
      "metadata": {
        "id": "7yjrVH3Bkj82"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-QeW9RSkSHb"
      },
      "outputs": [],
      "source": [
        "# Mount Drive so you can read datasets and write checkpoints\n",
        "# Link to dataset:\n",
        "# https://drive.google.com/drive/folders/1kygA17GiCeCs8qTeDBEndU6TkXnEu-m7?usp=drive_link\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q tensorflow matplotlib\n",
        "\n",
        "import string\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import layers, models, backend as K\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Dirs\n",
        "train_dir = \"/content/drive/MyDrive/MScProject/data/words3/train\"\n",
        "test_dir = \"/content/drive/MyDrive/MScProject/data/words3/test\"\n",
        "CKPT_DIR  = \"/content/drive/MyDrive/MScProject/ctc_ckpt_best.keras\"\"\n",
        "\n",
        "# image dimensions (same as your synthetic data)\n",
        "IMG_H = 64\n",
        "IMG_W = 64\n",
        "BATCH  = 64\n",
        "\n",
        "# CTC parameters\n",
        "CHARS        = list(string.ascii_uppercase)         # ['A', … 'Z']\n",
        "BLANK_LABEL  = 0                                    # CTC blank\n",
        "char_to_num  = {c:i+1 for i,c in enumerate(CHARS)}  # 'A'→1 … 'Z'→26\n",
        "num_to_char  = {i+1:c for i,c in enumerate(CHARS)}\n",
        "NUM_CLASSES  = len(CHARS) + 1                       # +1 for blank\n",
        "\n",
        "# max label length (3 letters)\n",
        "MAX_LABEL_LEN = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Pipeline for CTC**"
      ],
      "metadata": {
        "id": "-9to-MdYkotO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "inputs = {\n",
        "  \"image\":        image_tensor,           # (64,64,1)\n",
        "  \"label\":        label_seq,              # (MAX_LABEL_LEN,)\n",
        "  \"input_len\":    input_seq_len,          # (1,)  time steps after CNN\n",
        "  \"label_len\":    label_length,           # (1,)\n",
        "}\n",
        "\n",
        "def parse_image_and_label(path, label):\n",
        "    # path: string filepath, label: a 3-char string e.g. \"CAT\"\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "    img = tf.image.resize(img, [IMG_H, IMG_W])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "    # encode label string to ints\n",
        "    lbl = [char_to_num[c] for c in label]\n",
        "    lbl = tf.convert_to_tensor(lbl, dtype=tf.int32)\n",
        "    return img, lbl\n",
        "\n",
        "def prepare_for_ctc(image, label):\n",
        "    # image: (H,W,1), label: (MAX_LABEL_LEN,)\n",
        "    # compute input_length = number of time steps output by the CNN\n",
        "    # we'll build CNN so that time_steps = W//4 (two 2×2 pools).\n",
        "    time_steps = IMG_W // 4\n",
        "\n",
        "    return {\n",
        "        \"image\":      image,\n",
        "        \"label\":      label,\n",
        "        \"input_len\":  tf.cast(time_steps, tf.int32),\n",
        "        \"label_len\":  tf.shape(label)[0],\n",
        "    }, tf.zeros(())  # dummy y_true, since loss is in-model\n",
        "\n",
        "def make_dataset(\n",
        "    data_dir,\n",
        "    subset=None, # \"training\", \"validation\", or None (no split)\n",
        "    val_frac=0.2,\n",
        "    batch_size=BATCH,\n",
        "    img_size=(64, 64),\n",
        "    seed=42\n",
        "):\n",
        "    data_dir = Path(data_dir)\n",
        "    # 1) discover classes\n",
        "    class_names = sorted([p.name for p in data_dir.iterdir() if p.is_dir()])\n",
        "    class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
        "\n",
        "    # 2) collect filepaths + labels\n",
        "    filepaths, labels = [], []\n",
        "    for cls in class_names:\n",
        "        for img_path in (data_dir/cls).glob(\"*.png\"):\n",
        "            filepaths.append(str(img_path))\n",
        "            labels.append(class_to_idx[cls])\n",
        "\n",
        "    # 3) shuffle\n",
        "    combined = list(zip(filepaths, labels))\n",
        "    random.Random(seed).shuffle(combined)\n",
        "    filepaths, labels = zip(*combined)\n",
        "\n",
        "    # 4) split\n",
        "    if subset in (\"training\", \"validation\"):\n",
        "        n_val = int(len(filepaths) * val_frac)\n",
        "        if subset == \"validation\":\n",
        "            filepaths = filepaths[:n_val]\n",
        "            labels    = labels[:n_val]\n",
        "        else:\n",
        "            filepaths = filepaths[n_val:]\n",
        "            labels    = labels[n_val:]\n",
        "\n",
        "    # 5) build tf.data.Dataset\n",
        "    ds = tf.data.Dataset.from_tensor_slices((list(filepaths), list(labels)))\n",
        "\n",
        "    def _load_and_preprocess(path, label):\n",
        "        # Read + decode\n",
        "        img = tf.io.read_file(path)\n",
        "        img = tf.io.decode_image(img, channels=1, expand_animations=False)\n",
        "        # Resize + normalize\n",
        "        img = tf.image.resize(img, img_size)\n",
        "        img = img / 255.0\n",
        "        # one-hot encode label\n",
        "        label = tf.one_hot(label, depth=len(class_names))\n",
        "        return img, label\n",
        "\n",
        "    ds = ds.map(_load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # 6) shuffle training only\n",
        "    if subset == \"training\":\n",
        "        ds = ds.shuffle(buffer_size=1000, seed=seed)\n",
        "\n",
        "    # 7) batch & prefetch\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return ds, class_names\n",
        "\n",
        "train_ds, class_names   = make_dataset(train_dir, subset=\"training\")\n",
        "val_ds                  = make_dataset(train_dir, subset=\"validation\")\n",
        "test_ds                 = make_dataset(test_dir, subset=None)"
      ],
      "metadata": {
        "id": "4hBA30bRkqtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Build CTC Model**"
      ],
      "metadata": {
        "id": "chjCDXf9kq4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1. image input\n",
        "img_in = layers.Input(shape=(IMG_H,IMG_W,1), name=\"image\")\n",
        "\n",
        "# 3.2. convolutional feature extractor\n",
        "x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(img_in)\n",
        "x = layers.MaxPool2D(pool_size=2)(x)   # → (32×32×32)\n",
        "x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(pool_size=2)(x)   # → (16×16×64)\n",
        "\n",
        "# collapse height dimension to 1\n",
        "x = layers.Conv2D(128, (IMG_H//16,1), activation=\"relu\")(x)\n",
        "# → (1 × time_steps= IMG_W/4 × 128)\n",
        "x = layers.Reshape((IMG_W//4, 128))(x)\n",
        "\n",
        "# 3.3. Bi-LSTM sequence modelling\n",
        "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "\n",
        "# 3.4. output layer (softmax over characters + blank)\n",
        "y_pred = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"y_pred\")(x)\n",
        "\n",
        "# 3.5. additional inputs for CTC loss\n",
        "labels      = layers.Input(shape=(MAX_LABEL_LEN,), dtype=\"int32\", name=\"label\")\n",
        "input_len   = layers.Input(shape=(),              dtype=\"int32\", name=\"input_len\")\n",
        "label_len   = layers.Input(shape=(),              dtype=\"int32\", name=\"label_len\")\n",
        "\n",
        "# 3.6. CTC loss computation in-graph\n",
        "def ctc_lambda(args):\n",
        "    y_pred, labels, input_len, label_len = args\n",
        "    # swap batch and time for K.ctc_batch_cost signature\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_len, label_len)\n",
        "\n",
        "ctc_loss = layers.Lambda(ctc_lambda, output_shape=(1,), name=\"ctc\")(\n",
        "    [y_pred, labels, input_len, label_len]\n",
        ")\n",
        "\n",
        "# 3.7. training model\n",
        "training_model = models.Model(\n",
        "    inputs=[img_in, labels, input_len, label_len],\n",
        "    outputs=ctc_loss\n",
        ")\n",
        "\n",
        "training_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\"ctc\": lambda y_true, y_pred: y_pred}\n",
        ")\n",
        "\n",
        "# 3.8. inference model (for decoding later)\n",
        "inference_model = models.Model(img_in, y_pred)\n",
        "\n",
        "training_model.summary()"
      ],
      "metadata": {
        "id": "3D0R2n-FkwgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Train with CTC**"
      ],
      "metadata": {
        "id": "OAM8rdB0kxBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        CKPT_DIR,\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=3\n",
        "    )\n",
        "]\n",
        "\n",
        "history = training_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "-0L_aMCMk0HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Decode & Evaluate**"
      ],
      "metadata": {
        "id": "KrR1m1vBk1tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1. restore best\n",
        "tf.keras.config.enable_unsafe_deserialization()\n",
        "inference_model = tf.keras.models.load_model(\n",
        "    CKPT_DIR,\n",
        "    compile=False\n",
        ")\n",
        "inference_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "inference_model.summary()\n",
        "\n",
        "# 5.2. helper to convert preds→strings\n",
        "def decode_batch(batch_pred):\n",
        "    # batch_pred: (batch, time_steps, NUM_CLASSES)\n",
        "    input_length = np.ones(batch_pred.shape[0]) * batch_pred.shape[1]\n",
        "    # greedy ctc decode\n",
        "    decoded, _ = K.ctc_decode(batch_pred, input_length, greedy=True)\n",
        "    decoded = decoded[0].numpy()  # tensor → numpy\n",
        "    # map ints back to chars\n",
        "    texts = []\n",
        "    for seq in decoded:\n",
        "        s = \"\".join(num_to_char.get(i, \"\") for i in seq if i>0)\n",
        "        texts.append(s)\n",
        "    return texts\n",
        "\n",
        "# 5.3. run on test set\n",
        "y_true, y_pred = [], []\n",
        "for batch in test_ds:\n",
        "    inp = batch[0][\"image\"]\n",
        "    labels = batch[0][\"label\"].numpy().astype(int)\n",
        "    preds = inference_model.predict(inp)\n",
        "    texts = decode_batch(preds)\n",
        "    # flatten true labels to strings\n",
        "    for t, seq in zip(labels, texts):\n",
        "        true_str = \"\".join(num_to_char[i] for i in t if i>0)\n",
        "        y_true.append(true_str)\n",
        "        y_pred.append(seq)\n",
        "\n",
        "# 5.4. compute word-level accuracy\n",
        "print(\"Word accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(classification_report(y_true, y_pred, zero_division=0))"
      ],
      "metadata": {
        "id": "5rMEiqbWk3YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Visualisation**"
      ],
      "metadata": {
        "id": "8v8m51ESn9dW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(history, ft_history=None):\n",
        "    \"\"\"\n",
        "    Plots accuracy and loss curves.\n",
        "    If ft_history (fine-tune history) is provided, it will be appended.\n",
        "    \"\"\"\n",
        "    # merge histories if needed\n",
        "    h = history.history.copy()\n",
        "    if ft_history is not None:\n",
        "        for k, v in ft_history.history.items():\n",
        "            h[k].extend(v)\n",
        "\n",
        "    epochs = range(1, len(h['loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    # Accuracy\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epochs, h['accuracy'],    label='Train Acc')\n",
        "    plt.plot(epochs, h.get('val_accuracy', []), label='Val Acc')\n",
        "    plt.title('Accuracy over epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs, h['loss'],    label='Train Loss')\n",
        "    plt.plot(epochs, h.get('val_loss', []), label='Val Loss')\n",
        "    plt.title('Loss over epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion(cm, class_names, figsize=(8,8), fontsize=6):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix heatmap.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.colorbar(fraction=0.046, pad=0.04)\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=90, fontsize=fontsize)\n",
        "    plt.yticks(tick_marks, class_names, fontsize=fontsize)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "                 fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def show_sample_predictions(model, dataset, class_names, num=9):\n",
        "    \"\"\"\n",
        "    Displays num examples (default 9) from dataset alongside\n",
        "    their true & predicted labels, highlighting mistakes in red.\n",
        "    \"\"\"\n",
        "    # unbatch and take\n",
        "    ds = dataset.unbatch().take(num)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i, (img, label) in enumerate(ds):\n",
        "        pred = np.argmax(model.predict(img[None,...]), axis=1)[0]\n",
        "        true = np.argmax(label.numpy())\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.imshow(img.numpy().squeeze(), cmap='gray')\n",
        "        title = f\"T: {class_names[true]}\\nP: {class_names[pred]}\"\n",
        "        plt.title(title, color=('red' if pred!=true else 'black'), fontsize=10)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 1) Plot training curves.\n",
        "if \"ft_history\" in locals():\n",
        "    plot_training_curves(history, ft_history)\n",
        "else:\n",
        "    plot_training_curves(history)\n",
        "\n",
        "# 2) Evaluate on test set and build confusion matrix:\n",
        "y_true, y_pred = [], []\n",
        "for x, y in test_ds:\n",
        "    preds = word_model.predict(x)\n",
        "    y_pred.extend(preds.argmax(axis=1))\n",
        "    y_true.extend(y.numpy().argmax(axis=1))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion(cm, class_names, figsize=(12,12), fontsize=4)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# 3) Show a few prediction examples\n",
        "show_sample_predictions(word_model, test_ds, class_names, num=9)"
      ],
      "metadata": {
        "id": "Tl6nD9ayoC40"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab0c76-0daa-48ee-838e-d9e0a1c4907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for training the letter classification model\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich.live import Live\n",
    "from rich.layout import Layout\n",
    "\n",
    "from src.utils.config import load_config, get_model_config, get_training_config, get_data_config\n",
    "from src.data.data_loader import get_data_loaders\n",
    "from src.models.letter_classifier import get_model\n",
    "from src.trainer import Trainer\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize rich console\n",
    "console = Console()\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"\n",
    "    Set up the training device (GPU/CPU) based on availability.\n",
    "    Uses MPS for Apple Silicon, CUDA for NVIDIA GPUs, or falls back to CPU.\n",
    "    \"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        console.print(\"[green]GPU available: Using Metal Performance Shaders (MPS)[/green]\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        console.print(\"[green]GPU available: Using CUDA[/green]\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        console.print(\"[yellow]No GPU detected: Using CPU[/yellow]\")\n",
    "    return device\n",
    "\n",
    "def get_optimal_batch_size(image_size, available_memory_gb=None):\n",
    "    \"\"\"\n",
    "    Calculate optimal batch size based on available memory and image size.\n",
    "\n",
    "    Args:\n",
    "        image_size (tuple): Image dimensions (height, width)\n",
    "        available_memory_gb (float): Available GPU memory in GB. If None, estimates based on system.\n",
    "\n",
    "    Returns:\n",
    "        int: Optimal batch size\n",
    "    \"\"\"\n",
    "    # Estimate memory if not provided\n",
    "    if available_memory_gb is None:\n",
    "        if torch.backends.mps.is_available() or torch.cuda.is_available():\n",
    "            available_memory_gb = 16  # Conservative estimate for GPU memory\n",
    "        else:\n",
    "            available_memory_gb = 8   # Conservative estimate for CPU memory\n",
    "\n",
    "    # Calculate memory requirements per sample\n",
    "    bytes_per_pixel = 4  # float32\n",
    "    sample_memory = image_size[0] * image_size[1] * bytes_per_pixel\n",
    "\n",
    "    # Reserve 20% of memory for the model and other operations\n",
    "    usable_memory = available_memory_gb * 1e9 * 0.2\n",
    "\n",
    "    # Calculate batch size\n",
    "    optimal_batch_size = min(128, int(usable_memory / sample_memory))\n",
    "\n",
    "    # Ensure batch size is at least 16\n",
    "    return max(16, optimal_batch_size)\n",
    "\n",
    "def resume_training(trainer, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Resume training from a checkpoint if available.\n",
    "\n",
    "    Args:\n",
    "        trainer (Trainer): Training instance\n",
    "        checkpoint_path (Path): Path to checkpoint file\n",
    "    \"\"\"\n",
    "    if checkpoint_path.exists():\n",
    "        trainer.load_checkpoint(checkpoint_path)\n",
    "        console.print(f\"[green]Resumed training from {checkpoint_path}[/green]\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def monitor_memory():\n",
    "    \"\"\"\n",
    "    Monitor and log GPU/CPU memory usage during training.\n",
    "    Returns a formatted string with memory information.\n",
    "    \"\"\"\n",
    "    memory_info = []\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        try:\n",
    "            used_memory = torch.mps.current_allocated_memory() / 1e9\n",
    "            memory_info.append(f\"GPU Memory Used: {used_memory:.2f} GB\")\n",
    "        except:\n",
    "            memory_info.append(\"GPU Memory: Not available\")\n",
    "    elif torch.cuda.is_available():\n",
    "        try:\n",
    "            used_memory = torch.cuda.memory_allocated() / 1e9\n",
    "            total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            memory_info.append(f\"GPU Memory: {used_memory:.2f}GB / {total_memory:.2f}GB\")\n",
    "        except:\n",
    "            memory_info.append(\"GPU Memory: Not available\")\n",
    "    else:\n",
    "        import psutil\n",
    "        process = psutil.Process()\n",
    "        used_memory = process.memory_info().rss / 1e9\n",
    "        total_memory = psutil.virtual_memory().total / 1e9\n",
    "        memory_info.append(f\"CPU Memory: {used_memory:.2f}GB / {total_memory:.2f}GB\")\n",
    "\n",
    "    return \" | \".join(memory_info)\n",
    "\n",
    "def create_layout():\n",
    "    \"\"\"Create the layout for the training display.\"\"\"\n",
    "    layout = Layout()\n",
    "    layout.split(\n",
    "        Layout(name=\"header\", size=3),\n",
    "        Layout(name=\"body\"),\n",
    "        Layout(name=\"footer\", size=3)\n",
    "    )\n",
    "    return layout\n",
    "\n",
    "def create_header():\n",
    "    \"\"\"Create the header panel with training information.\"\"\"\n",
    "    return Panel(\n",
    "        \"[bold blue]Letter Classification Model Training[/bold blue]\",\n",
    "        style=\"white on blue\"\n",
    "    )\n",
    "\n",
    "def create_footer(epoch, total_epochs, train_loss, train_acc, val_loss, val_acc, lr):\n",
    "    \"\"\"Create the footer panel with current training metrics.\"\"\"\n",
    "    return Panel(\n",
    "        f\"Epoch: {epoch}/{total_epochs} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Train Acc: {train_acc:.2f}% | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Val Acc: {val_acc:.2f}% | \"\n",
    "        f\"LR: {lr:.6f}\",\n",
    "        style=\"white on blue\"\n",
    "    )\n",
    "\n",
    "def create_metrics_table(train_loss, train_acc, val_loss, val_acc):\n",
    "    \"\"\"Create a table with training metrics.\"\"\"\n",
    "    table = Table(title=\"Training Metrics\")\n",
    "    table.add_column(\"Metric\", style=\"cyan\")\n",
    "    table.add_column(\"Value\", style=\"green\")\n",
    "\n",
    "    table.add_row(\"Training Loss\", f\"{train_loss:.4f}\")\n",
    "    table.add_row(\"Training Accuracy\", f\"{train_acc:.2f}%\")\n",
    "    table.add_row(\"Validation Loss\", f\"{val_loss:.4f}\")\n",
    "    table.add_row(\"Validation Accuracy\", f\"{val_acc:.2f}%\")\n",
    "\n",
    "    return table\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for training the model.\"\"\"\n",
    "    # Load config\n",
    "    config_path = Path(\"configs/train_config.yaml\")\n",
    "    if not config_path.exists():\n",
    "        console.print(f\"[red]Config file not found: {config_path}[/red]\")\n",
    "        return\n",
    "\n",
    "    config = load_config(config_path)\n",
    "    model_config = get_model_config(config)\n",
    "    training_config = get_training_config(config)\n",
    "    data_config = get_data_config(config)\n",
    "\n",
    "    # Create output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = Path(\"outputs/letter_classifier\") / timestamp\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save config\n",
    "    with open(output_dir / \"config.yaml\", \"w\") as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "    # Calculate optimal batch size\n",
    "    optimal_batch_size = get_optimal_batch_size(model_config[\"input_shape\"][:2])\n",
    "    if optimal_batch_size != training_config[\"batch_size\"]:\n",
    "        console.print(f\"[yellow]Adjusting batch size from {training_config['batch_size']} to {optimal_batch_size} based on available memory[/yellow]\")\n",
    "        training_config[\"batch_size\"] = optimal_batch_size\n",
    "\n",
    "    # Create data loaders\n",
    "    console.print(\"\\n[bold cyan]Loading datasets...[/bold cyan]\")\n",
    "    data_loaders = get_data_loaders(\n",
    "        data_dir=\"data/characters\",\n",
    "        batch_size=training_config[\"batch_size\"],\n",
    "        image_size=model_config[\"input_shape\"][:2],\n",
    "        num_workers=4,\n",
    "        augment=data_config.get(\"augmentation\", {}).get(\"use\", True)\n",
    "    )\n",
    "\n",
    "    # Print dataset statistics\n",
    "    train_size = len(data_loaders[\"train\"].dataset)\n",
    "    val_size = len(data_loaders[\"val\"].dataset)\n",
    "    console.print(f\"\\n[green]Dataset Statistics:[/green]\")\n",
    "    console.print(f\"- Training set: {train_size:,} images\")\n",
    "    console.print(f\"- Validation set: {val_size:,} images\")\n",
    "    console.print(f\"- Batch size: {training_config['batch_size']}\")\n",
    "\n",
    "    # Create model\n",
    "    console.print(\"\\n[bold cyan]Initializing model...[/bold cyan]\")\n",
    "    model = get_model(model_config[\"architecture\"], model_config)\n",
    "    console.print(f\"- Input shape: {model_config['input_shape']}\")\n",
    "    console.print(f\"- Number of classes: {model_config['num_classes']}\")\n",
    "    console.print(f\"- Model architecture: {model_config['architecture']}\")\n",
    "\n",
    "    # Set up device\n",
    "    device = setup_device()\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=data_loaders[\"train\"],\n",
    "        val_loader=data_loaders[\"val\"],\n",
    "        config=training_config,\n",
    "        output_dir=output_dir,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Try to resume from checkpoint\n",
    "    checkpoint_path = output_dir / \"latest_checkpoint.pth\"\n",
    "    if resume_training(trainer, checkpoint_path):\n",
    "        console.print(\"[green]Successfully resumed training from checkpoint[/green]\")\n",
    "\n",
    "    # Create layout for training display\n",
    "    layout = create_layout()\n",
    "\n",
    "    # Start training with rich display\n",
    "    console.print(\"\\n[bold cyan]Starting training...[/bold cyan]\")\n",
    "    with Live(layout, refresh_per_second=4) as live:\n",
    "        for epoch in range(1, training_config[\"epochs\"] + 1):\n",
    "            # Update header\n",
    "            layout[\"header\"].update(create_header())\n",
    "\n",
    "            # Monitor and display memory usage\n",
    "            memory_status = monitor_memory()\n",
    "            console.print(f\"\\n[cyan]Memory Status: {memory_status}[/cyan]\")\n",
    "\n",
    "            # Train for one epoch\n",
    "            train_loss, train_acc = trainer.train_epoch()\n",
    "\n",
    "            # Validate\n",
    "            val_loss, val_acc, predictions, targets = trainer.validate()\n",
    "\n",
    "            # Update footer with current metrics\n",
    "            layout[\"footer\"].update(create_footer(\n",
    "                epoch, training_config[\"epochs\"],\n",
    "                train_loss, train_acc,\n",
    "                val_loss, val_acc,\n",
    "                trainer.optimizer.param_groups[0]['lr']\n",
    "            ))\n",
    "\n",
    "            # Update metrics table\n",
    "            layout[\"body\"].update(create_metrics_table(\n",
    "                train_loss, train_acc,\n",
    "                val_loss, val_acc\n",
    "            ))\n",
    "\n",
    "            # Save checkpoint and visualizations\n",
    "            if epoch % 5 == 0:\n",
    "                trainer.save_checkpoint(epoch)\n",
    "                # Monitor memory after checkpoint save\n",
    "                memory_status = monitor_memory()\n",
    "                console.print(f\"[cyan]Memory Status after checkpoint: {memory_status}[/cyan]\")\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                trainer.plot_confusion_matrix(predictions, targets, epoch)\n",
    "\n",
    "    # Save final model and plots\n",
    "    trainer.save_model(\"final\")\n",
    "    trainer.plot_history()\n",
    "\n",
    "    # Final memory status\n",
    "    memory_status = monitor_memory()\n",
    "    console.print(f\"\\n[cyan]Final Memory Status: {memory_status}[/cyan]\")\n",
    "\n",
    "    console.print(\"\\n[bold green]Training completed![/bold green]\")\n",
    "    console.print(f\"Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

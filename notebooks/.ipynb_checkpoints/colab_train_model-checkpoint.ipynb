{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cs-amy/project-codebase/blob/main/notebooks/colab_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nog1hADaZOK"
   },
   "source": [
    "# **MSc Project Model Training on Google Colab**\n",
    "`Author: Ashraf Muhammed Yusuf (23011173)`\n",
    "\n",
    "This notebook sets up the environment for training a letter classification model on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdOUGOlnaZOM"
   },
   "source": [
    "## 1. Clone the GitHub Repository\n",
    "\n",
    "First, clone the project's GitHub repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-0ls620aZOM"
   },
   "outputs": [],
   "source": [
    "# Delete the project-codebase directory if it exists\n",
    "!rm -rf project-codebase\n",
    "\n",
    "!git clone https://github.com/cs-amy/project-codebase.git\n",
    "%cd project-codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t8XlWpLaZOM"
   },
   "source": [
    "## 2. Mount Google Drive (for data files)\n",
    "\n",
    "If the project's data files are stored in Google Drive, mount it here.\n",
    "\n",
    "Note: If you do not already have the project data saved to your drive:\n",
    "\n",
    "\n",
    "1.   Access it here: https://drive.google.com/drive/folders/1sfNG1PkmTPBe1wOSQXZmfdkvR97Hn9lk?usp=sharing\n",
    "2.   Copy the entire folder to your drive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIaBlVzOaZON"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXHAQINrBS-o"
   },
   "outputs": [],
   "source": [
    "# Create symbolic links to the data directory\n",
    "!ln -s /content/drive/MyDrive/MScProject/data data\n",
    "\n",
    "print(\"Symbolic links created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd9Pq7TuaZON"
   },
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Install the required packages from the requirements.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReSHp1RgaZON"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "# Specific versions of PyTorch with CUDA support\n",
    "!pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cStl18DfaZON"
   },
   "source": [
    "## 4. Set Up Python Path\n",
    "\n",
    "Set up the python path correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34qpQFtlaZON"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/project-codebase')\n",
    "\n",
    "print(\"Python path set up successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t27Ha-3nOw9M"
   },
   "source": [
    "## 5. Library and Module Imports\n",
    "\n",
    "Ensure that the required libraries and project modules can be imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "L-nfmi6uO67l",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from rich.console import Console\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "\n",
    "# Module imports\n",
    "from src.models.letter_classifier import get_model\n",
    "from src.train.trainer import ModelTrainer\n",
    "from src.data.data_loader import DataLoader\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB46ZRFEaZON"
   },
   "source": [
    "## 6. Model Configuration\n",
    "Feel free to adjust these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLaLqnQBaZON"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"architecture\": \"LetterClassifierCNN\",\n",
    "        \"input_shape\": [28, 28, 1],  # Height, Width, Channels\n",
    "        \"num_classes\": 26,  # a-z\n",
    "        \"dropout_rate\": 0.5\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 64,  # Will be automatically adjusted based on available memory\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"lr_scheduler\": {\n",
    "            \"use\": True,\n",
    "            \"type\": \"reduce_on_plateau\",\n",
    "            \"patience\": 5,\n",
    "            \"factor\": 0.5,\n",
    "            \"min_lr\": 0.00001\n",
    "        },\n",
    "        \"early_stopping\": {\n",
    "            \"use\": True,\n",
    "            \"patience\": 15,\n",
    "            \"min_delta\": 0.001\n",
    "        }\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"regular\": {\n",
    "            \"train_dir\": \"data/characters/regular/train\",\n",
    "            \"test_dir\": \"data/characters/regular/test\"\n",
    "        },\n",
    "        \"obfuscated\": {\n",
    "            \"train_dir\": \"data/characters/obfuscated/train\",\n",
    "            \"test_dir\": \"data/characters/obfuscated/test\"\n",
    "        },\n",
    "        \"image_size\": [28, 28],  # Input image size (height, width)\n",
    "        \"validation_split\": 0.2,  # Portion of training data to use for validation\n",
    "        \"shuffle\": True,\n",
    "        \"augmentation\": {\n",
    "            \"use\": True,\n",
    "            \"rotation_range\": 10,\n",
    "            \"zoom_range\": 0.1,\n",
    "            \"width_shift_range\": 0.1,\n",
    "            \"height_shift_range\": 0.1,\n",
    "            \"brightness_range\": [0.8, 1.2],\n",
    "            \"random_noise\": 0.01\n",
    "        }\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"dir\": \"outputs/letter_classifier\",  # Relative to project root\n",
    "        \"save_frequency\": 5,  # Save checkpoint every N epochs\n",
    "        \"keep_best\": True   # Keep best model based on validation loss\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Model configuration set up successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNYpAuI6PsDN"
   },
   "source": [
    "## 7. Configure Logging\n",
    "Configure console logging for rich outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0naz-YXJP3Wa"
   },
   "outputs": [],
   "source": [
    "# Initialize rich console\n",
    "console = Console()\n",
    "\n",
    "console.print(\"[green]Logging configured successfully![/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf3WXIpfPdmC"
   },
   "source": [
    "## 8. Create Data Validation/Creation Routines\n",
    "Set up useful functions for dealing with datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgLaZq3rF296"
   },
   "outputs": [],
   "source": [
    "# Routine for validating directory structure\n",
    "def validate_data_directory(data_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Validate the data directory structure.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to the data/characters directory\n",
    "    \"\"\"\n",
    "    required_dirs = [\n",
    "        \"regular/train\",\n",
    "        \"regular/test\",\n",
    "        \"obfuscated/train\",\n",
    "        \"obfuscated/test\"\n",
    "    ]\n",
    "\n",
    "    missing_dirs = []\n",
    "    for dir_path in required_dirs:\n",
    "        full_path = data_dir / dir_path\n",
    "        if not full_path.exists():\n",
    "            missing_dirs.append(dir_path)\n",
    "\n",
    "    if missing_dirs:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing required directories in {data_dir}:\\n\" +\n",
    "            \"\\n\".join(f\"- {d}\" for d in missing_dirs)\n",
    "        )\n",
    "\n",
    "    # Log directory structure\n",
    "    console.print(\"[green]Data directory structure validation successful![/green]\")\n",
    "    console.print(f\"Root: {data_dir}\")\n",
    "    for dir_path in required_dirs:\n",
    "        full_path = data_dir / dir_path\n",
    "        num_files = len(list(full_path.glob(\"**/*.png\")))\n",
    "        console.print(f\"- {dir_path}: {num_files} PNG files\")\n",
    "\n",
    "\n",
    "class CharacterDataset(Dataset):\n",
    "    \"\"\"Dataset for character images (regular or obfuscated).\"\"\"\n",
    "\n",
    "    # Class-level character mapping\n",
    "    CHAR_TO_IDX = {chr(97 + i): i for i in range(26)}  # a-z to 0-25\n",
    "    IDX_TO_CHAR = {i: chr(97 + i) for i in range(26)}  # 0-25 to a-z\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str | Path,\n",
    "        image_size: Tuple[int, int] = (28, 28),\n",
    "        transform: Optional[transforms.Compose] = None,\n",
    "        is_training: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "\n",
    "        Args:\n",
    "            data_dir: Directory containing character images (e.g., data/characters/regular/train)\n",
    "            image_size: Target size for images (height, width)\n",
    "            transform: Optional additional transformations\n",
    "            is_training: Whether this is a training dataset\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        if not self.data_dir.exists():\n",
    "            raise FileNotFoundError(f\"Data directory not found: {self.data_dir}\")\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.is_training = is_training\n",
    "\n",
    "        # Get all character directories (a-z)\n",
    "        self.char_dirs = sorted([d for d in self.data_dir.iterdir() if d.is_dir()])\n",
    "        if not self.char_dirs:\n",
    "            raise ValueError(f\"No character directories found in {self.data_dir}\")\n",
    "\n",
    "        # Get all image paths and labels\n",
    "        self.images, self.labels = self._load_dataset()\n",
    "\n",
    "        # Set up transformations\n",
    "        self.transform = transform if transform is not None else self._get_default_transforms()\n",
    "\n",
    "        # Log dataset statistics\n",
    "        console.print(f\"[green]Loaded {len(self.images)} images from {self.data_dir}[/green]\")\n",
    "        char_counts = {char: sum(1 for l in self.labels if l == idx)\n",
    "                       for char, idx in self.CHAR_TO_IDX.items()}\n",
    "        console.print(\"[green]Character distribution:[/green]\")\n",
    "        for char, count in char_counts.items():\n",
    "            console.print(f\"- {char}: {count} images\")\n",
    "\n",
    "    def _load_dataset(self) -> Tuple[List[Path], List[int]]:\n",
    "        \"\"\"Load all image paths and their corresponding labels.\"\"\"\n",
    "        images, labels = [], []\n",
    "\n",
    "        for char_dir in self.char_dirs:\n",
    "            char = char_dir.name.lower()\n",
    "            if char not in self.CHAR_TO_IDX:\n",
    "                console.print(f\"[yellow]Skipping unknown character directory: {char}[/yellow]\")\n",
    "                continue\n",
    "\n",
    "            label = self.CHAR_TO_IDX[char]\n",
    "\n",
    "            # Get all PNG images in this directory\n",
    "            char_images = list(char_dir.glob(\"*.png\"))\n",
    "            images.extend(char_images)\n",
    "            labels.extend([label] * len(char_images))\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def _get_default_transforms(self) -> transforms.Compose:\n",
    "        \"\"\"Get default transformation pipeline.\"\"\"\n",
    "        transform_list = [\n",
    "            transforms.Resize(self.image_size),\n",
    "            transforms.Grayscale(1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ]\n",
    "\n",
    "        if self.is_training:\n",
    "            transform_list.insert(1, transforms.RandomRotation(10))\n",
    "            transform_list.insert(2, transforms.RandomAffine(\n",
    "                degrees=0,\n",
    "                translate=(0.1, 0.1),\n",
    "                scale=(0.9, 1.1)\n",
    "            ))\n",
    "\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"Get a single sample.\"\"\"\n",
    "        image_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load and convert image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "            image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]Error loading image {image_path}: {e}[/red]\")\n",
    "            # Return a blank image and the label if there's an error\n",
    "            return torch.zeros((1, *self.image_size)), label\n",
    "\n",
    "    @classmethod\n",
    "    def get_char_mapping(cls) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "        \"\"\"\n",
    "        Get the character to index and index to character mappings.\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (char_to_idx, idx_to_char) dictionaries\n",
    "        \"\"\"\n",
    "        return cls.CHAR_TO_IDX, cls.IDX_TO_CHAR\n",
    "\n",
    "\n",
    "def get_data_loaders(\n",
    "    data_dir: str | Path,\n",
    "    batch_size: int = 32,\n",
    "    image_size: Tuple[int, int] = (28, 28),\n",
    "    num_workers: int = 4,\n",
    "    augment: bool = True\n",
    ") -> Dict[str, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create data loaders for training, validation, and testing.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to the data/characters directory (e.g., data/characters)\n",
    "        batch_size: Batch size for training\n",
    "        image_size: Target size for images\n",
    "        num_workers: Number of worker processes for data loading\n",
    "        augment: Whether to use data augmentation (applied in training mode)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing train, val, and test data loaders.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "\n",
    "    # Validate directory structure\n",
    "    validate_data_directory(data_dir)\n",
    "\n",
    "    # Load training datasets for both regular and obfuscated characters\n",
    "    train_regular = CharacterDataset(\n",
    "        data_dir / \"regular\" / \"train\",\n",
    "        image_size=image_size,\n",
    "        is_training=True\n",
    "    )\n",
    "    train_obfuscated = CharacterDataset(\n",
    "        data_dir / \"obfuscated\" / \"train\",\n",
    "        image_size=image_size,\n",
    "        is_training=True\n",
    "    )\n",
    "\n",
    "    # Load test datasets for both regular and obfuscated characters\n",
    "    test_regular = CharacterDataset(\n",
    "        data_dir / \"regular\" / \"test\",\n",
    "        image_size=image_size,\n",
    "        is_training=False\n",
    "    )\n",
    "    test_obfuscated = CharacterDataset(\n",
    "        data_dir / \"obfuscated\" / \"test\",\n",
    "        image_size=image_size,\n",
    "        is_training=False\n",
    "    )\n",
    "\n",
    "    # Combine datasets for training and testing\n",
    "    train_dataset = ConcatDataset([train_regular, train_obfuscated])\n",
    "    test_dataset = ConcatDataset([test_regular, test_obfuscated])\n",
    "\n",
    "    # Create train/validation split (80/20) on the training dataset\n",
    "    train_length = int(0.8 * len(train_dataset))\n",
    "    val_length = len(train_dataset) - train_length\n",
    "    train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_length, val_length])\n",
    "\n",
    "    # Log dataset statistics\n",
    "    console.print(\"[green]Combined dataset statistics:[/green]\")\n",
    "    console.print(f\"- Training set: {len(train_subset)} images\")\n",
    "    console.print(f\"- Validation set: {len(val_subset)} images\")\n",
    "    console.print(f\"- Test set: {len(test_dataset)} images\")\n",
    "\n",
    "    # Create data loaders for each split\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": val_loader,\n",
    "        \"test\": test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7YtmyjWaZON"
   },
   "source": [
    "## 9. Train Model\n",
    "\n",
    "a. Set up training routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNsc1BZUaZON"
   },
   "outputs": [],
   "source": [
    "def setup_device():\n",
    "    \"\"\"\n",
    "    Set up the training device (GPU/CPU) based on availability.\n",
    "    Uses MPS for Apple Silicon, CUDA for NVIDIA GPUs, or falls back to CPU.\n",
    "    \"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        console.print(\"[green]GPU available: Using Metal Performance Shaders (MPS)[/green]\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        console.print(\"[green]GPU available: Using CUDA[/green]\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        console.print(\"[yellow]No GPU detected: Using CPU[/yellow]\")\n",
    "    return device\n",
    "\n",
    "def get_optimal_batch_size(image_size, available_memory_gb=None):\n",
    "    \"\"\"\n",
    "    Calculate optimal batch size based on available memory and image size.\n",
    "\n",
    "    Args:\n",
    "        image_size (tuple): Image dimensions (height, width)\n",
    "        available_memory_gb (float): Available GPU memory in GB. If None, estimates based on system.\n",
    "\n",
    "    Returns:\n",
    "        int: Optimal batch size\n",
    "    \"\"\"\n",
    "    # Estimate memory if not provided\n",
    "    if available_memory_gb is None:\n",
    "        if torch.backends.mps.is_available() or torch.cuda.is_available():\n",
    "            available_memory_gb = 16  # Conservative estimate for GPU memory\n",
    "        else:\n",
    "            available_memory_gb = 8   # Conservative estimate for CPU memory\n",
    "\n",
    "    # Calculate memory requirements per sample\n",
    "    bytes_per_pixel = 4  # float32\n",
    "    sample_memory = image_size[0] * image_size[1] * bytes_per_pixel\n",
    "\n",
    "    # Reserve 20% of memory for model and other operations\n",
    "    usable_memory = available_memory_gb * 1e9 * 0.2\n",
    "\n",
    "    # Calculate batch size, with a hard cap of 128\n",
    "    optimal_batch_size = min(128, int(usable_memory / sample_memory))\n",
    "\n",
    "    # Ensure batch size is at least 16\n",
    "    return max(16, optimal_batch_size)\n",
    "\n",
    "def resume_training(trainer, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Resume training from a checkpoint if available.\n",
    "\n",
    "    Args:\n",
    "        trainer (ModelTrainer): Training instance\n",
    "        checkpoint_path (Path): Path to checkpoint file\n",
    "    \"\"\"\n",
    "    if checkpoint_path.exists():\n",
    "        trainer.load_checkpoint(checkpoint_path)\n",
    "        console.print(f\"[green]Resumed training from {checkpoint_path}[/green]\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def train():\n",
    "    \"\"\"Main function for training the model using simple console output.\"\"\"\n",
    "    model_config = config.get(\"model\", {})\n",
    "    training_config = config.get(\"training\", {})\n",
    "    data_config = config.get(\"data\", {})\n",
    "\n",
    "    # Create output directory with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = Path(\"outputs/letter_classifier\") / timestamp\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save current config for reproducibility\n",
    "    with open(output_dir / \"config.yaml\", \"w\") as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "    # Calculate optimal batch size based on image dimensions\n",
    "    optimal_batch_size = get_optimal_batch_size(model_config[\"input_shape\"][:2])\n",
    "    if optimal_batch_size != training_config[\"batch_size\"]:\n",
    "        console.print(\n",
    "            f\"[yellow]Adjusting batch size from {training_config['batch_size']} to {optimal_batch_size} based on available memory[/yellow]\"\n",
    "        )\n",
    "        training_config[\"batch_size\"] = optimal_batch_size\n",
    "\n",
    "    # Create data loaders\n",
    "    console.print(\"\\n[bold cyan]Loading datasets...[/bold cyan]\")\n",
    "    # Assuming get_data_loaders is defined elsewhere\n",
    "    data_loaders = get_data_loaders(\n",
    "        data_dir=\"/content/drive/MyDrive/MScProject/data/characters\",\n",
    "        batch_size=training_config[\"batch_size\"],\n",
    "        image_size=model_config[\"input_shape\"][:2],\n",
    "        num_workers=4,\n",
    "        augment=data_config.get(\"augmentation\", {}).get(\"use\", True)\n",
    "    )\n",
    "\n",
    "    # Print dataset statistics\n",
    "    train_size = len(data_loaders[\"train\"].dataset)\n",
    "    val_size = len(data_loaders[\"val\"].dataset)\n",
    "    test_size = len(data_loaders[\"test\"].dataset)\n",
    "    console.print(f\"\\n[green]Dataset Statistics:[/green]\")\n",
    "    console.print(f\"- Training set: {train_size:,} images\")\n",
    "    console.print(f\"- Validation set: {val_size:,} images\")\n",
    "    console.print(f\"- Test set: {test_size:,} images\")\n",
    "    console.print(f\"- Batch size: {training_config['batch_size']}\")\n",
    "\n",
    "    # Create model (assuming get_model is defined and imported)\n",
    "    console.print(\"\\n[bold cyan]Initializing model...[/bold cyan]\")\n",
    "    model = get_model(model_config[\"architecture\"], model_config)\n",
    "    console.print(f\"- Input shape: {model_config['input_shape']}\")\n",
    "    console.print(f\"- Number of classes: {model_config['num_classes']}\")\n",
    "    console.print(f\"- Model architecture: {model_config['architecture']}\")\n",
    "\n",
    "    # Set up device\n",
    "    device = setup_device()\n",
    "\n",
    "    # Create trainer (assuming ModelTrainer is defined and imported)\n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        train_loader=data_loaders[\"train\"],\n",
    "        test_loader=data_loaders[\"val\"],\n",
    "        config=config,\n",
    "        output_dir=output_dir,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Optionally resume from checkpoint\n",
    "    checkpoint_path = output_dir / \"latest_checkpoint.pth\"\n",
    "    if resume_training(trainer, checkpoint_path):\n",
    "        console.print(\"[green]Successfully resumed training from checkpoint[/green]\")\n",
    "\n",
    "    console.print(\"\\n[bold cyan]Starting training...[/bold cyan]\")\n",
    "    # Training loop with simple console prints\n",
    "    for epoch in range(1, training_config[\"epochs\"] + 1):\n",
    "        # Train\n",
    "        train_loss, train_acc = trainer.train_epoch()\n",
    "        # Validate\n",
    "        val_loss, val_acc = trainer.validate()\n",
    "\n",
    "        # Print epoch metrics\n",
    "        console.print(\n",
    "            f\"Epoch {epoch}/{training_config['epochs']}: \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}% | \"\n",
    "            f\"LR: {trainer.optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        )\n",
    "\n",
    "        # Save checkpoint every 5 epochs\n",
    "        if epoch % training_config.get(\"save_frequency\", 5) == 0:\n",
    "            trainer.save_checkpoint(epoch)\n",
    "            console.print(f\"[green]Checkpoint saved at epoch {epoch}[/green]\")\n",
    "\n",
    "        # Plot confusion matrix every 10 epochs (if implemented)\n",
    "        # if epoch % 10 == 0:\n",
    "        #     trainer.plot_confusion_matrix(predictions, targets, epoch)\n",
    "\n",
    "    # Save final model and plots\n",
    "    trainer.save_model(\"final\")\n",
    "    trainer.plot_history()\n",
    "\n",
    "    console.print(\"\\n[bold green]Training completed![/bold green]\")\n",
    "    console.print(f\"Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsaqDiMeQwas"
   },
   "source": [
    "b. Start model taining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txynyz8j8VX4"
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDqXoZpYaZON"
   },
   "source": [
    "## 10. Save Results to Google Drive (optional)\n",
    "\n",
    "Save the trained model and results to Google Drive for persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQmg7BV_aZON"
   },
   "outputs": [],
   "source": [
    "# Create directory for results if it doesn't exist\n",
    "!mkdir -p /content/drive/MyDrive/MScProject/results\n",
    "\n",
    "# Copy results to Google Drive\n",
    "!cp -r results/* /content/drive/MyDrive/MScProject/results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "name": "MSc Project Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

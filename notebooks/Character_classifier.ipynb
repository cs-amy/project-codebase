{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMLY3lEO+abSh/EmkS8Ojzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs-amy/project-codebase/blob/main/notebooks/Character_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model for Character De-Obfuscation**\n",
        "Stage 1 of MSc Project — Ashraf Muhammed Yusuf"
      ],
      "metadata": {
        "id": "qB1MMygGJSIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Colab Environment Setup**"
      ],
      "metadata": {
        "id": "-Z1sGlcxkWFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q tensorflow matplotlib\n",
        "\n",
        "# Import dependencies\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import layers, models, callbacks, mixed_precision\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Mount Drive so you can read datasets and write checkpoints\n",
        "# Link to dataset:\n",
        "# https://drive.google.com/drive/folders/1sfNG1PkmTPBe1wOSQXZmfdkvR97Hn9lk?usp=sharing\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# (Optional—but useful) turn on XLA JIT for extra speed\n",
        "tf.config.optimizer.set_jit(True)"
      ],
      "metadata": {
        "id": "PxaFJf7RgUiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Loading & Splitting**\n",
        "We'll use Keras's image_dataset_from_directory to build train/validation and test sets."
      ],
      "metadata": {
        "id": "EYLkqjfUleL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH = 64\n",
        "IMG_SIZE = (64, 64)\n",
        "BASE_DIR=\"/content/drive/MyDrive/MScProject\"\n",
        "CKPT_DIR=f\"{BASE_DIR}/char_ckpt_best.keras\"\n",
        "train_dir = f\"{BASE_DIR}/data/characters/train\"\n",
        "test_dir = f\"{BASE_DIR}/data/characters/test\"\n",
        "\n",
        "# Train dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SIZE,\n",
        "  color_mode=\"grayscale\",\n",
        "  validation_split=0.20,\n",
        "  subset=\"training\",\n",
        "  seed=42\n",
        ")\n",
        "\n",
        "# Val dataset\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SIZE,\n",
        "  color_mode=\"grayscale\",\n",
        "  validation_split=0.20,\n",
        "  subset=\"validation\",\n",
        "  seed=42\n",
        ")\n",
        "\n",
        "# Test dataset\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  labels=\"inferred\",\n",
        "  label_mode=\"categorical\",\n",
        "  batch_size=BATCH,\n",
        "  image_size=IMG_SIZE,\n",
        "  color_mode=\"grayscale\",\n",
        "  shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "OWX12CXSlwA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility to display examples from each set\n",
        "def show_examples(ds, ds_name, num=5):\n",
        "  # Take one batch\n",
        "  for images, labels in ds.take(1):\n",
        "    images = images.numpy()\n",
        "    labels = labels.numpy()\n",
        "    class_names = ds.class_names\n",
        "    break\n",
        "\n",
        "  plt.figure(figsize=(6,6))\n",
        "  for i in range(num):\n",
        "    ax = plt.subplot(3, 3, i+1)\n",
        "    img = images[i].squeeze()  # shape: (H,W) since grayscale\n",
        "    lbl = class_names[labels[i].argmax()]\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"{ds_name}: {lbl}\")\n",
        "    plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# Display 5 examples from each split\n",
        "show_examples(train_ds, \"Train\")\n",
        "show_examples(val_ds, \"Val\")\n",
        "show_examples(test_ds, \"Test\")"
      ],
      "metadata": {
        "id": "JhdMrFp2OSNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Preprocessing & Augmentation**"
      ],
      "metadata": {
        "id": "S_sH7vX5mZ09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset class names before piping the dataset through 'map'\n",
        "train_ds_class_names = test_ds.class_names\n",
        "val_ds_class_names = test_ds.class_names\n",
        "test_ds_class_names = test_ds.class_names\n",
        "\n",
        "# Normalize and augment datasets (only the train dataset is augmented)\n",
        "normalization = layers.Rescaling(1./255)\n",
        "aug = tf.keras.Sequential([\n",
        "  layers.RandomRotation(0.1),\n",
        "  layers.RandomZoom(0.1),\n",
        "  layers.RandomTranslation(0.1, 0.1)\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x,y: (aug(normalization(x)), y))\n",
        "val_ds   = val_ds.map(lambda x,y: (normalization(x), y))\n",
        "test_ds  = test_ds.map(lambda x,y: (normalization(x), y))"
      ],
      "metadata": {
        "id": "bNHG90gcA-mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall pydot\n",
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install -y graphviz"
      ],
      "metadata": {
        "id": "0-q55ImLcyn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Architecture**\n",
        "We will define a simple yet robust CNN (grayscale)"
      ],
      "metadata": {
        "id": "k3dpHNLTmj6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "\n",
        "# 1. Input Layer\n",
        "inputs = layers.Input(shape=(*IMG_SIZE, 1))\n",
        "\n",
        "# 2. (Conv + ReLU) + Pooling 1\n",
        "x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "\n",
        "# 3. (Conv + ReLU) + Pooling 2\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D()(x)\n",
        "\n",
        "# 4. (Conv + ReLU)\n",
        "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
        "\n",
        "# 5. Flatten to Vector\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# 6. (FC + ReLU) Layer\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# 7. Dropout Regularisation\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# 8. Output Layer\n",
        "outputs = layers.Dense(26, activation='softmax')(x)\n",
        "\n",
        "# Construct model\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Show model summary\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1DI5pTqmmu8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Compilation & Callbacks**"
      ],
      "metadata": {
        "id": "XBjFMxNOmz_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "# 1. Checkpoint - saves the best model\n",
        "ckpt = callbacks.ModelCheckpoint(\n",
        "  filepath=CKPT_DIR,\n",
        "  save_best_only=True,\n",
        "  monitor=\"val_loss\" # keep only the best model\n",
        ")\n",
        "# 2. Early stopping\n",
        "es = callbacks.EarlyStopping(\n",
        "  monitor=\"val_loss\",\n",
        "  patience=6, # stop ~6 epochs after val_loss stalls\n",
        "  restore_best_weights=True\n",
        ")\n",
        "\n",
        "# 3. LR scheduler\n",
        "lr_s = callbacks.ReduceLROnPlateau(\n",
        "  monitor=\"val_loss\",\n",
        "  factor=0.5,\n",
        "  patience=3, # halve LR if val_loss hasn’t improved for 3 epochs\n",
        "  min_lr=1e-6\n",
        ")\n",
        "\n",
        "callbacks=[ckpt, es, lr_s]"
      ],
      "metadata": {
        "id": "RCwR3loom2z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Training**"
      ],
      "metadata": {
        "id": "ZMA2hu0im55n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=50,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "D63OYOFHp410"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Evaluation & Visualisation**"
      ],
      "metadata": {
        "id": "ZPvzZN7Sm-ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best checkpoint's weights\n",
        "model.load_weights(CKPT_DIR)\n",
        "\n",
        "# Test model accuracy on test dataset\n",
        "model.evaluate(test_ds)\n",
        "\n",
        "# Training curves\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, history.history['accuracy'],    label='train_acc')\n",
        "plt.plot(epochs, history.history['val_accuracy'],label='val_acc')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, history.history['loss'],    label='train_loss')\n",
        "plt.plot(epochs, history.history['val_loss'],label='val_loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "nFntT7z9nCmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Confusion Matrix & Classification Report**"
      ],
      "metadata": {
        "id": "sQXB87S-qYod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather all ground-truths and predictions\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for batch_x, batch_y in test_ds:\n",
        "  preds = model.predict(batch_x)\n",
        "  y_pred.extend(np.argmax(preds, axis=1))\n",
        "  y_true.extend(np.argmax(batch_y.numpy(), axis=1))\n",
        "\n",
        "class_names = test_ds_class_names\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(train_ds_class_names))\n",
        "plt.xticks(tick_marks, train_ds_class_names, rotation=90)\n",
        "plt.yticks(tick_marks, train_ds_class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x6XoURWfnLiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Display Misclassified Examples**"
      ],
      "metadata": {
        "id": "JCvdCMn9rUrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First flatten all test images to a single array\n",
        "images_all = np.concatenate([x.numpy() for x, y in test_ds], axis=0)\n",
        "mis_idx = [i for i, (t, p) in enumerate(zip(y_true, y_pred)) if t!=p]\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "for i, idx in enumerate(mis_idx[:9]):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  img = images_all[idx].squeeze()\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.title(f\"T:{class_names[y_true[idx]]} P:{class_names[y_pred[idx]]}\")\n",
        "  plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2bwliZqcrXpu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
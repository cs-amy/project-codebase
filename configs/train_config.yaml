# Training configuration for letter classifier

# Model Configuration
model:
  architecture: "LetterClassifierCNN"
  input_shape: [28, 28, 1]  # Height, Width, Channels
  num_classes: 26  # a-z
  dropout_rate: 0.5

# Training Configuration
training:
  epochs: 100
  batch_size: 64  # Will be automatically adjusted based on available memory
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: "adam"
  scheduler:
    use: true
    type: "reduce_on_plateau"
    patience: 5
    factor: 0.5
    min_lr: 0.00001
  early_stopping:
    use: true
    patience: 15
    min_delta: 0.001

# Data Configuration
data:
  # Dataset paths (relative to project root)
  regular:
    train_dir: "data/characters/regular/train"
    test_dir: "data/characters/regular/test"
  obfuscated:
    train_dir: "data/characters/obfuscated/train"
    test_dir: "data/characters/obfuscated/test"
  
  # Image settings
  image_size: [28, 28]  # Input image size (height, width)
  
  # Dataset settings
  validation_split: 0.2  # Portion of training data to use for validation
  shuffle: true
  
  # Data augmentation settings
  augmentation:
    use: true
    rotation_range: 10
    zoom_range: 0.1
    width_shift_range: 0.1
    height_shift_range: 0.1
    brightness_range: [0.8, 1.2]
    random_noise: 0.01

# Output Configuration
output:
  dir: "outputs/letter_classifier"  # Relative to project root
  save_frequency: 5  # Save checkpoint every N epochs
  keep_best: true   # Keep best model based on validation loss
